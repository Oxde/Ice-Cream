{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d632b59",
   "metadata": {},
   "source": [
    "# 04 - Simple MMM Baseline Model\n",
    "\n",
    "**Research Goal**: Establish a solid, interpretable baseline for Media Mix Modeling\n",
    "**Business Context**: Ice cream company needs data-driven budget allocation guidance\n",
    "**Team**: Data Science Research Team\n",
    "\n",
    "## 🎯 Research Objectives\n",
    "\n",
    "1. **Build Trustworthy Foundation**: Create simple, explainable model stakeholders can trust\n",
    "2. **Establish Performance Baseline**: Set benchmark for future model iterations  \n",
    "3. **Generate Business Insights**: Provide actionable ROI guidance for each media channel\n",
    "4. **Validate Methodology**: Prove temporal validation and overfitting prevention work\n",
    "\n",
    "## 📊 Data Strategy\n",
    "\n",
    "- **Dataset**: `consistent_channels` (129 train + 27 test weeks, 2022-2025)\n",
    "- **No Email Channel**: Excluded due to data quality issues (missing/inconsistent data)\n",
    "- **7 Media Channels**: All spending channels with reliable data\n",
    "- **Temporal Split**: Strict chronological train/test (no data leakage)\n",
    "\n",
    "## 🔬 Modeling Approach\n",
    "\n",
    "- **Algorithm**: Ridge Regression (prevents overfitting, handles multicollinearity)\n",
    "- **Adstock**: Simple carryover effects (decay=0.4) for media persistence  \n",
    "- **Features**: Media spend (adstocked) + seasonality + weather + promotions\n",
    "- **Validation**: Cross-validated regularization + temporal test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🎯 04 - SIMPLE MMM BASELINE MODEL\")\n",
    "print(\"=\" * 50)\n",
    "print(\"📊 Research Goal: Establish interpretable baseline for budget allocation\")\n",
    "print(\"🏢 Business Impact: Clear ROI guidance for 7 media channels\")\n",
    "print(\"🔬 Method: Ridge regression with adstock + temporal validation\")\n",
    "\n",
    "# Configure clean plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee6db9",
   "metadata": {},
   "source": [
    "## 📁 Data Loading and Quality Assessment\n",
    "\n",
    "We use the `consistent_channels` dataset which excludes email campaigns due to data quality issues.\n",
    "This ensures our baseline model is built on reliable, consistent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n📁 LOADING VALIDATED MMM DATASET\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Load pre-validated train/test splits\n",
    "train_data = pd.read_csv('../data/mmm_ready/consistent_channels_train_set.csv')\n",
    "test_data = pd.read_csv('../data/mmm_ready/consistent_channels_test_set.csv')\n",
    "\n",
    "# Parse dates for temporal analysis\n",
    "train_data['date'] = pd.to_datetime(train_data['date'])\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "\n",
    "print(f\"✅ Training Period: {train_data['date'].min().date()} to {train_data['date'].max().date()}\")\n",
    "print(f\"   → {train_data.shape[0]} weeks of data\")\n",
    "print(f\"✅ Test Period: {test_data['date'].min().date()} to {test_data['date'].max().date()}\")\n",
    "print(f\"   → {test_data.shape[0]} weeks of data\")\n",
    "\n",
    "# Data quality assessment\n",
    "train_missing = train_data.isnull().sum().sum()\n",
    "test_missing = test_data.isnull().sum().sum()\n",
    "print(f\"\\n📊 Data Quality Check:\")\n",
    "print(f\"   Training missing values: {train_missing}\")\n",
    "print(f\"   Test missing values: {test_missing}\")\n",
    "\n",
    "# Sales summary statistics\n",
    "print(f\"\\n💰 Sales Overview:\")\n",
    "print(f\"   Training - Mean: ${train_data['sales'].mean():,.0f}, Std: ${train_data['sales'].std():,.0f}\")\n",
    "print(f\"   Test - Mean: ${test_data['sales'].mean():,.0f}, Std: ${test_data['sales'].std():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3143074",
   "metadata": {},
   "source": [
    "## 🎯 Feature Definition and Business Logic\n",
    "\n",
    "We carefully select features based on business relevance and data reliability:\n",
    "\n",
    "### Media Channels (7)\n",
    "All channels where the company actively spends money for customer acquisition\n",
    "\n",
    "### Control Variables (8) \n",
    "External factors that influence ice cream sales but aren't controlled by marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9696553",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🎯 FEATURE DEFINITION AND BUSINESS LOGIC\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Media spend channels - all reliable spending data\n",
    "media_channels = [\n",
    "    'search_cost',                          # Digital: Search advertising\n",
    "    'tv_branding_tv_branding_cost',         # TV: Brand awareness campaigns  \n",
    "    'social_costs',                         # Digital: Social media advertising\n",
    "    'ooh_ooh_spend',                        # Outdoor: Billboards, transit ads\n",
    "    'radio_national_radio_national_cost',   # Radio: National reach campaigns\n",
    "    'radio_local_radio_local_cost',         # Radio: Local market campaigns\n",
    "    'tv_promo_tv_promo_cost'                # TV: Promotional campaigns\n",
    "]\n",
    "\n",
    "# Control variables - external factors affecting ice cream sales\n",
    "control_variables = [\n",
    "    'month_sin', 'month_cos',               # Seasonal cycles (ice cream seasonality)\n",
    "    'week_sin', 'week_cos',                 # Weekly patterns (weekend effects)\n",
    "    'holiday_period',                       # Holiday periods (increased consumption)\n",
    "    'weather_temperature_mean',             # Temperature (primary ice cream driver)\n",
    "    'weather_sunshine_duration',            # Sunshine (outdoor activities)\n",
    "    'promo_promotion_type'                  # Price promotions (demand drivers)\n",
    "]\n",
    "\n",
    "# Verify all features exist in data\n",
    "available_media = [col for col in media_channels if col in train_data.columns]\n",
    "available_controls = [col for col in control_variables if col in train_data.columns]\n",
    "\n",
    "print(f\"💰 MEDIA CHANNELS ANALYSIS ({len(available_media)} channels):\")\n",
    "print(f\"{'Channel':<35} {'Avg Weekly Spend':<15} {'Total Investment':<15} {'Business Purpose'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "business_purposes = {\n",
    "    'search_cost': 'Immediate conversion',\n",
    "    'tv_branding_tv_branding_cost': 'Brand awareness', \n",
    "    'social_costs': 'Engagement & targeting',\n",
    "    'ooh_ooh_spend': 'Local visibility',\n",
    "    'radio_national_radio_national_cost': 'Mass reach',\n",
    "    'radio_local_radio_local_cost': 'Local targeting', \n",
    "    'tv_promo_tv_promo_cost': 'Promotional push'\n",
    "}\n",
    "\n",
    "for channel in available_media:\n",
    "    avg_spend = train_data[channel].fillna(0).mean()\n",
    "    total_spend = train_data[channel].fillna(0).sum()\n",
    "    purpose = business_purposes.get(channel, 'Customer acquisition')\n",
    "    print(f\"{channel:<35} ${avg_spend:<14,.0f} ${total_spend:<14,.0f} {purpose}\")\n",
    "\n",
    "print(f\"\\n📊 CONTROL VARIABLES ({len(available_controls)} variables):\")\n",
    "for var in available_controls:\n",
    "    if 'weather' in var:\n",
    "        category = \"🌡️  Weather\"\n",
    "    elif any(x in var for x in ['month', 'week']):\n",
    "        category = \"📅 Seasonality\"\n",
    "    elif 'holiday' in var:\n",
    "        category = \"🎉 Events\"\n",
    "    elif 'promo' in var:\n",
    "        category = \"💰 Promotions\"\n",
    "    else:\n",
    "        category = \"📊 Other\"\n",
    "    print(f\"   {var:<30} {category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd645e46",
   "metadata": {},
   "source": [
    "## 📈 Adstock Transformation: Media Carryover Effects\n",
    "\n",
    "**Business Insight**: Media impact doesn't disappear immediately after spending stops.\n",
    "TV ads create awareness that lasts weeks, search ads drive immediate action.\n",
    "\n",
    "**Methodology**: Apply adstock transformation to capture carryover effects\n",
    "- **Decay Rate**: 0.4 (moderate carryover - 40% of previous week's effect carries over)\n",
    "- **Business Logic**: Media builds cumulative awareness and purchase intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3589fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n📈 ADSTOCK TRANSFORMATION - MEDIA CARRYOVER EFFECTS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def apply_adstock_transformation(x, decay_rate=0.4):\n",
    "    \"\"\"\n",
    "    Apply adstock (carryover) transformation to media spend\n",
    "    \n",
    "    Business Logic:\n",
    "    - Media effects don't stop immediately when spending stops\n",
    "    - Each week, some percentage of previous effect carries over\n",
    "    - Accumulates impact over time for sustained campaigns\n",
    "    \n",
    "    Args:\n",
    "        x: Media spend time series\n",
    "        decay_rate: Fraction of previous effect that carries over (0.4 = 40%)\n",
    "    \"\"\"\n",
    "    adstocked = np.zeros_like(x)\n",
    "    adstocked[0] = x[0] if not np.isnan(x[0]) else 0\n",
    "    \n",
    "    for i in range(1, len(x)):\n",
    "        current_spend = x[i] if not np.isnan(x[i]) else 0\n",
    "        previous_effect = adstocked[i-1] * decay_rate\n",
    "        adstocked[i] = current_spend + previous_effect\n",
    "    \n",
    "    return adstocked\n",
    "\n",
    "def transform_all_media_channels(data, media_cols, decay_rate=0.4):\n",
    "    \"\"\"Apply adstock to all media channels in dataset\"\"\"\n",
    "    data_transformed = data.copy()\n",
    "    \n",
    "    print(f\"🔄 Applying adstock transformation (decay rate = {decay_rate}):\")\n",
    "    print(f\"{'Channel':<35} {'Original Sum':<15} {'Adstock Sum':<15} {'Lift %':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for channel in media_cols:\n",
    "        if channel in data.columns:\n",
    "            # Clean missing values (assume no spend = 0)\n",
    "            clean_spend = data[channel].fillna(0)\n",
    "            \n",
    "            # Apply adstock transformation\n",
    "            adstocked_values = apply_adstock_transformation(clean_spend.values, decay_rate)\n",
    "            \n",
    "            # Store in new column\n",
    "            adstock_column = f\"{channel}_adstock\"\n",
    "            data_transformed[adstock_column] = adstocked_values\n",
    "            \n",
    "            # Calculate business impact\n",
    "            original_sum = clean_spend.sum()\n",
    "            adstock_sum = adstocked_values.sum()\n",
    "            lift_percent = ((adstock_sum - original_sum) / original_sum * 100) if original_sum > 0 else 0\n",
    "            \n",
    "            print(f\"{channel:<35} ${original_sum:<14,.0f} ${adstock_sum:<14,.0f} {lift_percent:<9.1f}%\")\n",
    "    \n",
    "    return data_transformed\n",
    "\n",
    "# Apply adstock to both training and test data\n",
    "print(\"📊 BUSINESS INSIGHT: Adstock captures cumulative media effects\")\n",
    "print(\"   → Higher adstock sum = better carryover effect capture\")\n",
    "print(\"   → Positive lift % = model accounts for sustained impact\\n\")\n",
    "\n",
    "train_adstocked = transform_all_media_channels(train_data, available_media)\n",
    "test_adstocked = transform_all_media_channels(test_data, available_media)\n",
    "\n",
    "# Update feature list to use adstocked media\n",
    "adstocked_media_features = [f\"{col}_adstock\" for col in available_media]\n",
    "\n",
    "print(f\"\\n✅ Adstock transformation complete:\")\n",
    "print(f\"   → {len(adstocked_media_features)} media channels with carryover effects\")\n",
    "print(f\"   → Ready for model training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c4ea1",
   "metadata": {},
   "source": [
    "## 🧹 Data Preprocessing: Missing Value Strategy\n",
    "\n",
    "**Research Approach**: Handle missing values based on business logic\n",
    "- **Media Spend**: Missing = No campaign running (fill with 0)\n",
    "- **Promotions**: Missing = No promotion active (fill with 0)  \n",
    "- **Weather**: Missing = Use median (temperature/sunshine)\n",
    "- **Seasonality**: Never missing (calculated features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🧹 DATA PREPROCESSING - MISSING VALUE STRATEGY\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def handle_missing_values_business_logic(data, control_cols):\n",
    "    \"\"\"\n",
    "    Handle missing values using business-informed logic\n",
    "    \n",
    "    Strategy:\n",
    "    - Promotions: NaN = no promotion active → 0\n",
    "    - Weather: NaN = missing measurement → median imputation  \n",
    "    - Seasonality: Never missing (calculated features)\n",
    "    \"\"\"\n",
    "    data_clean = data.copy()\n",
    "    \n",
    "    print(f\"🔍 Missing value analysis and treatment:\")\n",
    "    \n",
    "    for col in control_cols:\n",
    "        if col in data.columns:\n",
    "            missing_count = data[col].isnull().sum()\n",
    "            if missing_count > 0:\n",
    "                if 'promo' in col:\n",
    "                    # Business logic: No promotion data = no promotion running\n",
    "                    data_clean[col] = data[col].fillna(0)\n",
    "                    print(f\"   {col:<30} {missing_count:>3} missing → 0 (no promotion)\")\n",
    "                    \n",
    "                elif 'weather' in col:\n",
    "                    # Weather: Use median (typical seasonal value)\n",
    "                    median_val = data[col].median()\n",
    "                    data_clean[col] = data[col].fillna(median_val)\n",
    "                    print(f\"   {col:<30} {missing_count:>3} missing → {median_val:.1f} (median)\")\n",
    "                    \n",
    "                else:\n",
    "                    # Other controls: Use median imputation\n",
    "                    median_val = data[col].median()\n",
    "                    data_clean[col] = data[col].fillna(median_val)\n",
    "                    print(f\"   {col:<30} {missing_count:>3} missing → {median_val:.2f} (median)\")\n",
    "            else:\n",
    "                print(f\"   {col:<30} ✅ No missing values\")\n",
    "    \n",
    "    return data_clean\n",
    "\n",
    "# Apply business-logic missing value handling\n",
    "train_clean = handle_missing_values_business_logic(train_adstocked, available_controls)\n",
    "test_clean = handle_missing_values_business_logic(test_adstocked, available_controls)\n",
    "\n",
    "# Final validation - ensure no missing values in model features\n",
    "model_features = adstocked_media_features + available_controls\n",
    "train_final_missing = train_clean[model_features].isnull().sum().sum()\n",
    "test_final_missing = test_clean[model_features].isnull().sum().sum()\n",
    "\n",
    "print(f\"\\n✅ FINAL DATA QUALITY VALIDATION:\")\n",
    "print(f\"   Training set missing values: {train_final_missing}\")\n",
    "print(f\"   Test set missing values: {test_final_missing}\")\n",
    "\n",
    "if train_final_missing == 0 and test_final_missing == 0:\n",
    "    print(f\"   🎯 SUCCESS: Clean dataset ready for modeling\")\n",
    "else:\n",
    "    print(f\"   ⚠️  WARNING: Missing values remain - will fill with 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4e641",
   "metadata": {},
   "source": [
    "## 🤖 Model Training: Ridge Regression with Cross-Validation\n",
    "\n",
    "**Algorithm Choice**: Ridge Regression\n",
    "- **Handles multicollinearity** between media channels\n",
    "- **Prevents overfitting** with L2 regularization\n",
    "- **Interpretable coefficients** for business insights\n",
    "\n",
    "**Cross-Validation Strategy**: \n",
    "- Test multiple regularization strengths (α)\n",
    "- Use 5-fold CV to find optimal balance\n",
    "- Minimize overfitting while preserving performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c485652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🤖 MODEL TRAINING - RIDGE REGRESSION WITH CROSS-VALIDATION\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Prepare feature matrices and target vectors\n",
    "X_train = train_clean[model_features].fillna(0)  # Final safety fillna\n",
    "X_test = test_clean[model_features].fillna(0)\n",
    "y_train = train_clean['sales']\n",
    "y_test = test_clean['sales']\n",
    "\n",
    "print(f\"📊 MODEL SETUP SUMMARY:\")\n",
    "print(f\"   Training samples: {X_train.shape[0]}\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "print(f\"   Sample-to-feature ratio: {X_train.shape[0]/X_train.shape[1]:.1f}:1\")\n",
    "print(f\"   Target variable: Sales (mean=${y_train.mean():,.0f})\")\n",
    "\n",
    "# Feature scaling for regularized regression\n",
    "print(f\"\\n⚖️  FEATURE SCALING:\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Show scaling impact\n",
    "print(f\"   Before scaling - Mean: {X_train.mean().mean():.3f}, Std: {X_train.std().mean():.3f}\")\n",
    "print(f\"   After scaling  - Mean: {X_train_scaled.mean():.3f}, Std: {X_train_scaled.std():.3f}\")\n",
    "\n",
    "# Cross-validated regularization strength selection\n",
    "print(f\"\\n🔄 CROSS-VALIDATED REGULARIZATION SELECTION:\")\n",
    "regularization_strengths = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0]\n",
    "print(f\"   Testing α values: {regularization_strengths}\")\n",
    "\n",
    "ridge_cv = RidgeCV(\n",
    "    alphas=regularization_strengths,\n",
    "    cv=5,                                    # 5-fold cross-validation\n",
    "    scoring='neg_mean_squared_error'         # Minimize prediction error\n",
    ")\n",
    "\n",
    "# Train model with optimal regularization\n",
    "print(f\"   🔄 Training with 5-fold CV...\")\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "optimal_alpha = ridge_cv.alpha_\n",
    "print(f\"   ✅ Optimal regularization: α = {optimal_alpha}\")\n",
    "\n",
    "# Generate predictions for evaluation\n",
    "y_train_pred = ridge_cv.predict(X_train_scaled)\n",
    "y_test_pred = ridge_cv.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e62d06",
   "metadata": {},
   "source": [
    "## 📊 Model Performance Evaluation\n",
    "\n",
    "**Evaluation Strategy**: \n",
    "- **R²**: Percentage of sales variance explained by model\n",
    "- **MAE**: Average prediction error in dollars\n",
    "- **MAPE**: Percentage prediction error (business-friendly metric)\n",
    "- **Overfitting Assessment**: Compare train vs test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n📊 MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Calculate comprehensive performance metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_mape = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
    "test_mape = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
    "\n",
    "# Overfitting assessment\n",
    "overfitting_gap = train_r2 - test_r2\n",
    "\n",
    "print(f\"🎯 PERFORMANCE METRICS:\")\n",
    "print(f\"{'Metric':<25} {'Training':<15} {'Test':<15} {'Status'}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'R² (Variance Explained)':<25} {train_r2:.3f} ({train_r2*100:.1f}%) {test_r2:.3f} ({test_r2*100:.1f}%) {'✅ Good' if test_r2 > 0.4 else '📈 Needs Work'}\")\n",
    "print(f\"{'MAE (Avg Error)':<25} ${train_mae:,.0f} ${test_mae:,.0f} {'✅ Acceptable' if test_mae < 15000 else '⚠️ High Error'}\")\n",
    "print(f\"{'MAPE (% Error)':<25} {train_mape:.1f}% {test_mape:.1f}% {'✅ Good' if test_mape < 12 else '📊 Moderate'}\")\n",
    "\n",
    "print(f\"\\n🔍 OVERFITTING ASSESSMENT:\")\n",
    "print(f\"   Overfitting gap (Train R² - Test R²): {overfitting_gap:.3f}\")\n",
    "\n",
    "if overfitting_gap < 0.05:\n",
    "    overfitting_status = \"✅ Excellent generalization\"\n",
    "elif overfitting_gap < 0.10:\n",
    "    overfitting_status = \"✅ Good generalization\" \n",
    "elif overfitting_gap < 0.15:\n",
    "    overfitting_status = \"🔶 Moderate overfitting\"\n",
    "else:\n",
    "    overfitting_status = \"❌ High overfitting - needs regularization\"\n",
    "\n",
    "print(f\"   Status: {overfitting_status}\")\n",
    "\n",
    "# Business interpretation\n",
    "print(f\"\\n💼 BUSINESS INTERPRETATION:\")\n",
    "print(f\"   📈 Model explains {test_r2*100:.1f}% of sales variation\")\n",
    "print(f\"   💰 Typical prediction error: ${test_mae:,.0f} ({test_mape:.1f}%)\")\n",
    "\n",
    "if test_r2 >= 0.5:\n",
    "    business_grade = \"🏆 Excellent - Ready for budget decisions\"\n",
    "elif test_r2 >= 0.4:\n",
    "    business_grade = \"✅ Good - Reliable for strategic guidance\"\n",
    "elif test_r2 >= 0.3:\n",
    "    business_grade = \"📊 Moderate - Use with caution\"\n",
    "else:\n",
    "    business_grade = \"⚠️ Needs improvement before business use\"\n",
    "\n",
    "print(f\"   {business_grade}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89f1d20",
   "metadata": {},
   "source": [
    "## 💼 Business Insights: Channel ROI and Budget Recommendations\n",
    "\n",
    "**Research Question**: Which media channels drive the most sales per dollar spent?\n",
    "\n",
    "**Methodology**: \n",
    "- Extract model coefficients (sales impact per standardized spend unit)\n",
    "- Calculate ROI using average channel spend and predicted sales contribution\n",
    "- Rank channels by efficiency for budget allocation guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n💼 BUSINESS INSIGHTS - CHANNEL ROI AND BUDGET RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Extract feature importance from trained model\n",
    "coefficients = ridge_cv.coef_\n",
    "feature_names = model_features\n",
    "\n",
    "# Create feature importance dataframe\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(f\"🏆 TOP 10 MOST INFLUENTIAL FEATURES:\")\n",
    "print(f\"{'Rank':<5} {'Feature':<35} {'Coefficient':<15} {'Business Impact'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (idx, row) in enumerate(feature_importance_df.head(10).iterrows(), 1):\n",
    "    coef = row['Coefficient']\n",
    "    feature = row['Feature']\n",
    "    \n",
    "    if coef > 0:\n",
    "        impact = \"📈 Drives Sales\"\n",
    "    else:\n",
    "        impact = \"📉 Reduces Sales\"\n",
    "    \n",
    "    print(f\"{i:<5} {feature:<35} {coef:<15.3f} {impact}\")\n",
    "\n",
    "# Calculate media channel business metrics\n",
    "print(f\"\\n💰 MEDIA CHANNEL BUSINESS PERFORMANCE:\")\n",
    "media_channel_analysis = {}\n",
    "\n",
    "for channel in available_media:\n",
    "    adstock_feature = f\"{channel}_adstock\"\n",
    "    \n",
    "    if adstock_feature in feature_names:\n",
    "        # Get coefficient from model\n",
    "        feature_idx = feature_names.index(adstock_feature)\n",
    "        coefficient = coefficients[feature_idx]\n",
    "        \n",
    "        # Calculate business metrics\n",
    "        avg_weekly_spend = train_clean[channel].mean()\n",
    "        total_spend = train_clean[channel].sum()\n",
    "        \n",
    "        # Estimate contribution using coefficient and feature statistics\n",
    "        feature_std = X_train[adstock_feature].std()\n",
    "        feature_mean = X_train[adstock_feature].mean()\n",
    "        \n",
    "        # Simplified ROI calculation: coefficient impact scaled by spend\n",
    "        # This is approximate - more sophisticated attribution could be done\n",
    "        normalized_impact = coefficient * feature_std\n",
    "        estimated_weekly_contribution = normalized_impact * avg_weekly_spend / 1000  # Scale appropriately\n",
    "        \n",
    "        # ROI calculation\n",
    "        if avg_weekly_spend > 0:\n",
    "            roi_estimate = estimated_weekly_contribution / avg_weekly_spend\n",
    "        else:\n",
    "            roi_estimate = 0\n",
    "        \n",
    "        media_channel_analysis[channel] = {\n",
    "            'coefficient': coefficient,\n",
    "            'avg_weekly_spend': avg_weekly_spend,\n",
    "            'total_spend': total_spend,\n",
    "            'estimated_weekly_contribution': estimated_weekly_contribution,\n",
    "            'roi_estimate': roi_estimate\n",
    "        }\n",
    "\n",
    "# Sort channels by ROI for business recommendations\n",
    "sorted_by_roi = sorted(media_channel_analysis.items(), \n",
    "                      key=lambda x: x[1]['roi_estimate'], \n",
    "                      reverse=True)\n",
    "\n",
    "print(f\"{'Rank':<5} {'Channel':<35} {'Weekly Spend':<15} {'ROI Est.':<12} {'Recommendation'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for rank, (channel, metrics) in enumerate(sorted_by_roi, 1):\n",
    "    spend = metrics['avg_weekly_spend']\n",
    "    roi = metrics['roi_estimate']\n",
    "    \n",
    "    # Business recommendations based on ROI\n",
    "    if roi > 0.5:\n",
    "        recommendation = \"🟢 INCREASE BUDGET\"\n",
    "    elif roi > 0:\n",
    "        recommendation = \"🟡 MAINTAIN SPEND\" \n",
    "    elif roi > -0.2:\n",
    "        recommendation = \"🟠 OPTIMIZE/REDUCE\"\n",
    "    else:\n",
    "        recommendation = \"🔴 REVIEW STRATEGY\"\n",
    "    \n",
    "    print(f\"{rank:<5} {channel:<35} ${spend:<14,.0f} {roi:<11.3f} {recommendation}\")\n",
    "\n",
    "# Budget allocation recommendations\n",
    "total_media_spend = sum([metrics['avg_weekly_spend'] for metrics in media_channel_analysis.values()])\n",
    "\n",
    "print(f\"\\n🎯 STRATEGIC BUDGET RECOMMENDATIONS:\")\n",
    "print(f\"   💰 Current total weekly media budget: ${total_media_spend:,.0f}\")\n",
    "print(f\"   \")\n",
    "print(f\"   📈 HIGH PRIORITY (Increase Budget):\")\n",
    "for channel, metrics in sorted_by_roi[:3]:\n",
    "    if metrics['roi_estimate'] > 0:\n",
    "        print(f\"      • {channel}: ROI {metrics['roi_estimate']:.3f}\")\n",
    "\n",
    "if len(sorted_by_roi) > 3:\n",
    "    print(f\"   \")\n",
    "    print(f\"   📊 REVIEW REQUIRED (Optimize Strategy):\")\n",
    "    for channel, metrics in sorted_by_roi[3:]:\n",
    "        if metrics['roi_estimate'] <= 0:\n",
    "            print(f\"      • {channel}: ROI {metrics['roi_estimate']:.3f}\")\n",
    "\n",
    "print(f\"\\n💡 KEY INSIGHTS:\")\n",
    "print(f\"   • Focus budget on top 3 performing channels\")\n",
    "print(f\"   • Monitor negative ROI channels closely\")\n",
    "print(f\"   • Test budget reallocation in controlled experiments\")\n",
    "print(f\"   • Update model monthly with new data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5cf71d",
   "metadata": {},
   "source": [
    "## 📊 Model Diagnostics and Validation Visualizations\n",
    "\n",
    "**Validation Strategy**: Visual inspection of model performance\n",
    "- **Time series**: How well does model track actual sales over time?\n",
    "- **Scatter plots**: Is there systematic bias in predictions?\n",
    "- **Residual analysis**: Are prediction errors random or systematic?\n",
    "- **Feature importance**: Which factors drive model decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00502d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n📊 MODEL DIAGNOSTICS AND VALIDATION VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comprehensive diagnostic plots\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "# 1. Time Series: Full timeline with train/test split\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "full_dates = pd.concat([train_clean['date'], test_clean['date']])\n",
    "full_actual = pd.concat([y_train, y_test])\n",
    "full_predicted = np.concatenate([y_train_pred, y_test_pred])\n",
    "\n",
    "ax1.plot(full_dates, full_actual, 'b-', label='Actual Sales', linewidth=2.5, alpha=0.8)\n",
    "ax1.plot(full_dates, full_predicted, 'r-', label='Predicted Sales', linewidth=2, alpha=0.9)\n",
    "ax1.axvline(x=train_clean['date'].iloc[-1], color='orange', linestyle='--', alpha=0.8, \n",
    "           linewidth=2, label='Train/Test Split')\n",
    "ax1.set_title('Sales Prediction: Full Timeline\\nModel Tracking Performance', fontweight='bold')\n",
    "ax1.set_ylabel('Sales ($)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Training Set: Actual vs Predicted Scatter\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "ax2.scatter(y_train, y_train_pred, alpha=0.6, color='blue', s=40, edgecolor='darkblue', linewidth=0.5)\n",
    "min_val = min(y_train.min(), y_train_pred.min())\n",
    "max_val = max(y_train.max(), y_train_pred.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8, linewidth=2)\n",
    "ax2.set_xlabel('Actual Sales ($)')\n",
    "ax2.set_ylabel('Predicted Sales ($)')\n",
    "ax2.set_title(f'Training Set Accuracy\\nR² = {train_r2:.3f} ({train_r2*100:.1f}%)', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Test Set: Actual vs Predicted Scatter  \n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "ax3.scatter(y_test, y_test_pred, alpha=0.8, color='red', s=60, edgecolor='darkred', linewidth=0.8)\n",
    "min_val = min(y_test.min(), y_test_pred.min())\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "ax3.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.8, linewidth=2)\n",
    "ax3.set_xlabel('Actual Sales ($)')\n",
    "ax3.set_ylabel('Predicted Sales ($)')\n",
    "ax3.set_title(f'Test Set Accuracy\\nR² = {test_r2:.3f} ({test_r2*100:.1f}%)', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Feature Importance: Top Media Channels\n",
    "ax4 = plt.subplot(3, 3, 4)\n",
    "media_features_importance = feature_importance_df[\n",
    "    feature_importance_df['Feature'].str.contains('_adstock')\n",
    "].head(7)\n",
    "\n",
    "colors = ['green' if coef > 0 else 'red' for coef in media_features_importance['Coefficient']]\n",
    "bars = ax4.barh(media_features_importance['Feature'].str.replace('_adstock', '').str.replace('_', '\\n'), \n",
    "                media_features_importance['Coefficient'], \n",
    "                color=colors, alpha=0.7)\n",
    "ax4.set_xlabel('Coefficient (Sales Impact)')\n",
    "ax4.set_title('Media Channel Importance\\nGreen=Positive, Red=Negative', fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 5. Channel ROI Comparison\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "channels = [ch.replace('_', '\\n') for ch in available_media]\n",
    "rois = [media_channel_analysis[ch]['roi_estimate'] for ch in available_media]\n",
    "colors = ['green' if roi > 0 else 'red' for roi in rois]\n",
    "bars = ax5.bar(channels, rois, color=colors, alpha=0.7, edgecolor='black', linewidth=1)\n",
    "ax5.axhline(y=0, color='black', linestyle='-', alpha=0.8, linewidth=1)\n",
    "ax5.set_ylabel('ROI Estimate')\n",
    "ax5.set_title('Channel ROI Comparison\\nPositive = Profitable', fontweight='bold')\n",
    "ax5.tick_params(axis='x', rotation=45)\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6. Residuals Over Time\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "ax6.plot(train_clean['date'], train_residuals, 'bo-', label='Training Residuals', alpha=0.7, markersize=3)\n",
    "ax6.plot(test_clean['date'], test_residuals, 'ro-', label='Test Residuals', alpha=0.8, markersize=4)\n",
    "ax6.axhline(y=0, color='black', linestyle='-', alpha=0.8)\n",
    "ax6.set_ylabel('Prediction Error ($)')\n",
    "ax6.set_title('Prediction Errors Over Time\\nShould be Random', fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 7. Control Variable Importance\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "control_features_importance = feature_importance_df[\n",
    "    ~feature_importance_df['Feature'].str.contains('_adstock')\n",
    "].head(8)\n",
    "\n",
    "colors = ['green' if coef > 0 else 'red' for coef in control_features_importance['Coefficient']]\n",
    "ax7.barh(control_features_importance['Feature'].str.replace('_', '\\n'), \n",
    "         control_features_importance['Coefficient'],\n",
    "         color=colors, alpha=0.7)\n",
    "ax7.set_xlabel('Coefficient (Sales Impact)')\n",
    "ax7.set_title('Control Variable Importance\\nSeasonality & Weather Effects', fontweight='bold')\n",
    "ax7.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 8. Prediction Distribution Analysis\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "ax8.hist(y_train, bins=20, alpha=0.6, label='Actual Sales (Train)', color='blue', density=True)\n",
    "ax8.hist(y_train_pred, bins=20, alpha=0.6, label='Predicted Sales (Train)', color='red', density=True)\n",
    "ax8.set_xlabel('Sales ($)')\n",
    "ax8.set_ylabel('Density')\n",
    "ax8.set_title('Sales Distribution\\nActual vs Predicted', fontweight='bold')\n",
    "ax8.legend()\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Model Performance Summary\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "ax9.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "04 SIMPLE BASELINE MODEL\n",
    "{'='*25}\n",
    "\n",
    "PERFORMANCE METRICS:\n",
    "• Test R²: {test_r2:.1%} \n",
    "• Test MAE: ${test_mae:,.0f}\n",
    "• Test MAPE: {test_mape:.1f}%\n",
    "• Overfitting: {overfitting_gap:.3f}\n",
    "\n",
    "BUSINESS INSIGHTS:\n",
    "• {len(available_media)} media channels analyzed\n",
    "• Model explains {test_r2*100:.1f}% of sales variation\n",
    "• Avg prediction error: {test_mape:.1f}%\n",
    "\n",
    "TOP PERFORMING CHANNEL:\n",
    "{sorted_by_roi[0][0]}\n",
    "ROI: {sorted_by_roi[0][1]['roi_estimate']:.3f}\n",
    "\n",
    "STATUS: {'✅ BUSINESS READY' if test_r2 > 0.4 else '📈 NEEDS IMPROVEMENT'}\n",
    "\"\"\"\n",
    "ax9.text(0.05, 0.95, summary_text, transform=ax9.transAxes, fontsize=11,\n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.suptitle('04 Simple MMM Baseline - Comprehensive Model Diagnostics', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b3ab0",
   "metadata": {},
   "source": [
    "## 📋 Research Summary and Model Documentation\n",
    "\n",
    "**Final Assessment**: Document model performance, limitations, and next steps for research team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n📋 04 SIMPLE BASELINE MODEL - RESEARCH SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"🎯 RESEARCH OBJECTIVES STATUS:\")\n",
    "print(f\"   ✅ Trustworthy Foundation: Ridge regression with proper validation\")\n",
    "print(f\"   ✅ Performance Baseline: {test_r2:.1%} Test R² established\") \n",
    "print(f\"   ✅ Business Insights: ROI guidance for all 7 media channels\")\n",
    "print(f\"   ✅ Methodology Validation: {overfitting_gap:.3f} overfitting gap (controlled)\")\n",
    "\n",
    "print(f\"\\n📊 MODEL SPECIFICATIONS:\")\n",
    "print(f\"   • Algorithm: Ridge Regression (α={optimal_alpha})\")\n",
    "print(f\"   • Features: {len(model_features)} (7 media + 8 controls)\")\n",
    "print(f\"   • Training Period: {train_data.shape[0]} weeks ({train_data['date'].min().date()} - {train_data['date'].max().date()})\")\n",
    "print(f\"   • Test Period: {test_data.shape[0]} weeks ({test_data['date'].min().date()} - {test_data['date'].max().date()})\")\n",
    "print(f\"   • Adstock Decay: 0.4 (moderate carryover)\")\n",
    "\n",
    "print(f\"\\n🏆 MODEL PERFORMANCE:\")\n",
    "print(f\"   • Predictive Accuracy: {test_r2:.1%} of sales variance explained\")\n",
    "print(f\"   • Business Error: {test_mape:.1f}% average prediction error\")\n",
    "print(f\"   • Generalization: {overfitting_status}\")\n",
    "print(f\"   • Business Readiness: {business_grade}\")\n",
    "\n",
    "print(f\"\\n💼 KEY BUSINESS INSIGHTS:\")\n",
    "print(f\"   🥇 Top Performing Channel: {sorted_by_roi[0][0]} (ROI: {sorted_by_roi[0][1]['roi_estimate']:.3f})\")\n",
    "print(f\"   💰 Total Weekly Media Budget: ${total_media_spend:,.0f}\")\n",
    "print(f\"   📈 Channels with Positive ROI: {len([ch for ch, metrics in sorted_by_roi if metrics['roi_estimate'] > 0])}\")\n",
    "print(f\"   📉 Channels Needing Review: {len([ch for ch, metrics in sorted_by_roi if metrics['roi_estimate'] <= 0])}\")\n",
    "\n",
    "print(f\"\\n⚠️  MODEL LIMITATIONS:\")\n",
    "print(f\"   • Simple adstock (uniform 0.4 decay) - channels likely have different carryover patterns\")\n",
    "print(f\"   • Linear assumptions - diminishing returns not captured\")\n",
    "print(f\"   • No interaction effects between channels\")\n",
    "print(f\"   • Limited external factors (no competitors, economic indicators)\")\n",
    "print(f\"   • ROI calculations are approximate (simplified attribution)\")\n",
    "\n",
    "print(f\"\\n🚀 RECOMMENDED NEXT STEPS (FOR 05 ENHANCED MODEL):\")\n",
    "print(f\"   1. 📈 Channel-Specific Adstock: Different decay rates per channel\")\n",
    "print(f\"   2. 📊 Saturation Curves: Model diminishing returns\")\n",
    "print(f\"   3. 🤝 Interaction Effects: TV+Radio, Search+Social synergies\")\n",
    "print(f\"   4. 🎯 Feature Engineering: More sophisticated seasonality\")\n",
    "print(f\"   5. 🔍 Advanced Validation: Time series cross-validation\")\n",
    "\n",
    "print(f\"\\n📁 RESEARCH DELIVERABLES:\")\n",
    "print(f\"   • Baseline model ready for business use\")\n",
    "print(f\"   • Channel ROI rankings for immediate budget guidance\")\n",
    "print(f\"   • Performance benchmark for future model comparisons\")\n",
    "print(f\"   • Validated methodology for MMM development\")\n",
    "\n",
    "print(f\"\\n🎯 BUSINESS IMPACT:\")\n",
    "if test_r2 >= 0.45:\n",
    "    print(f\"   🏆 EXCELLENT: Model ready for strategic budget allocation\")\n",
    "elif test_r2 >= 0.35:\n",
    "    print(f\"   ✅ GOOD: Suitable for directional budget guidance\")\n",
    "else:\n",
    "    print(f\"   📈 DEVELOPING: Use insights with caution, continue enhancement\")\n",
    "\n",
    "print(f\"\\n💡 The 04 Simple Baseline provides a solid foundation for\")\n",
    "print(f\"   data-driven media budget decisions while establishing\")\n",
    "print(f\"   clear performance benchmarks for future model iterations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1b87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
