{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b0c7cf",
   "metadata": {},
   "source": [
    "# Dual Data Unification - Two Strategic Datasets\n",
    "\n",
    "**STRATEGIC APPROACH**: Create two unified datasets for comparison\n",
    "\n",
    "**Dataset A - Full Range**: 2022-2024 (9 channels, 156 weeks)\n",
    "- Excludes email (missing 2024)\n",
    "- Maximum data volume and recency\n",
    "- Better for trend analysis\n",
    "\n",
    "**Dataset B - Complete Coverage**: 2022-2023 (10 channels, 104 weeks)\n",
    "- Includes all channels including email\n",
    "- Complete attribution modeling\n",
    "- Better for channel interaction analysis\n",
    "\n",
    "**Goal**: Enable data-driven decision on which approach works better for MMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be5d10e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 DUAL DATA UNIFICATION - Strategic Comparison\n",
      "============================================================\n",
      "📅 Started at: 2025-05-28 03:22:53\n",
      "\n",
      "🎯 CREATING TWO STRATEGIC DATASETS:\n",
      "   📊 Dataset A: Full Range (2022-2024, 9 channels)\n",
      "   📊 Dataset B: Complete Coverage (2022-2023, 10 channels)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"🔗 DUAL DATA UNIFICATION - Strategic Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📅 Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "print(\"🎯 CREATING TWO STRATEGIC DATASETS:\")\n",
    "print(\"   📊 Dataset A: Full Range (2022-2024, 9 channels)\")\n",
    "print(\"   📊 Dataset B: Complete Coverage (2022-2023, 10 channels)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80365a5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 LOADING PREPROCESSED DATASETS\n",
      "========================================\n",
      "Found 10 preprocessed datasets:\n",
      "  ✅ email: (104, 14) | 2022-01-03 to 2023-12-25\n",
      "  ✅ sales: (156, 14) | 2022-01-03 to 2024-12-23\n",
      "  ✅ search: (156, 15) | 2022-01-03 to 2024-12-23\n",
      "  ✅ tv_branding: (156, 15) | 2022-01-03 to 2024-12-23\n",
      "  ✅ social: (156, 15) | 2022-01-03 to 2024-12-23\n",
      "  ✅ ooh: (156, 14) | 2022-01-03 to 2024-12-23\n",
      "  ✅ promo: (47, 14) | 2022-01-10 to 2024-11-04\n",
      "  ✅ radio_national: (156, 15) | 2022-01-03 to 2024-12-23\n",
      "  ✅ radio_local: (156, 15) | 2022-01-03 to 2024-12-23\n",
      "  ✅ tv_promo: (156, 15) | 2022-01-03 to 2024-12-23\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load All Preprocessed Datasets\n",
    "def load_preprocessed_datasets():\n",
    "    \"\"\"\n",
    "    Load all preprocessed datasets from the processed directory\n",
    "    \"\"\"\n",
    "    print(f\"\\n📂 LOADING PREPROCESSED DATASETS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    processed_dir = '../data/processed'\n",
    "    datasets = {}\n",
    "    \n",
    "    # Find all preprocessed CSV files\n",
    "    csv_files = [f for f in os.listdir(processed_dir) if f.endswith('_preprocessed.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"❌ No preprocessed files found!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} preprocessed datasets:\")\n",
    "    \n",
    "    for file in csv_files:\n",
    "        # Extract dataset name (remove _preprocessed.csv)\n",
    "        dataset_name = file.replace('_preprocessed.csv', '')\n",
    "        file_path = os.path.join(processed_dir, file)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Convert date column if it exists\n",
    "            if 'date' in df.columns:\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            datasets[dataset_name] = df\n",
    "            \n",
    "            # Display info\n",
    "            date_range = f\"{df['date'].min().date()} to {df['date'].max().date()}\" if 'date' in df.columns else \"No date\"\n",
    "            print(f\"  ✅ {dataset_name}: {df.shape} | {date_range}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error loading {file}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Load all datasets\n",
    "preprocessed_datasets = load_preprocessed_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf28658",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 STRATEGIC DATASET ANALYSIS\n",
      "==================================================\n",
      "\n",
      "📊 DATASET A - FULL RANGE:\n",
      "   📅 Period: 2022-01-03 to 2024-12-23\n",
      "   📈 Duration: ~156 weeks (3 years)\n",
      "   📊 Channels: 9 (excludes email - missing 2024)\n",
      "\n",
      "📊 DATASET B - COMPLETE COVERAGE:\n",
      "   📅 Period: 2022-01-03 to 2023-12-25\n",
      "   📈 Duration: ~104 weeks (2 years)\n",
      "   📊 Channels: 10 (includes all channels)\n",
      "\n",
      "🔍 DATASET COMPATIBILITY ANALYSIS:\n",
      "  email:\n",
      "    Range: 2022-01-03 to 2023-12-25\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  sales:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  search:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  tv_branding:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  social:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  ooh:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  promo:\n",
      "    Range: 2022-01-10 to 2024-11-04\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  radio_national:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  radio_local:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "  tv_promo:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): ✅\n",
      "    Strategy B (2022-2023): ✅\n",
      "\n",
      "📋 FINAL DATASET COMPOSITIONS:\n",
      "  Strategy A: 10 datasets - ['email', 'sales', 'search', 'tv_branding', 'social', 'ooh', 'promo', 'radio_national', 'radio_local', 'tv_promo']\n",
      "  Strategy B: 10 datasets - ['email', 'sales', 'search', 'tv_branding', 'social', 'ooh', 'promo', 'radio_national', 'radio_local', 'tv_promo']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define Date Ranges and Dataset Compositions\n",
    "def analyze_dataset_strategies(datasets_dict):\n",
    "    \"\"\"\n",
    "    Analyze the two strategic approaches\n",
    "    \"\"\"\n",
    "    print(f\"\\n🎯 STRATEGIC DATASET ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not datasets_dict:\n",
    "        print(\"❌ No datasets to analyze!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Define date ranges\n",
    "    FULL_RANGE_START = '2022-01-03'\n",
    "    FULL_RANGE_END = '2024-12-23'\n",
    "    COMPLETE_RANGE_START = '2022-01-03'\n",
    "    COMPLETE_RANGE_END = '2023-12-25'\n",
    "    \n",
    "    print(f\"\\n📊 DATASET A - FULL RANGE:\")\n",
    "    print(f\"   📅 Period: {FULL_RANGE_START} to {FULL_RANGE_END}\")\n",
    "    print(f\"   📈 Duration: ~156 weeks (3 years)\")\n",
    "    print(f\"   📊 Channels: 9 (excludes email - missing 2024)\")\n",
    "    \n",
    "    print(f\"\\n📊 DATASET B - COMPLETE COVERAGE:\")\n",
    "    print(f\"   📅 Period: {COMPLETE_RANGE_START} to {COMPLETE_RANGE_END}\")\n",
    "    print(f\"   📈 Duration: ~104 weeks (2 years)\")\n",
    "    print(f\"   📊 Channels: 10 (includes all channels)\")\n",
    "    \n",
    "    # Analyze which datasets fit each strategy\n",
    "    strategy_a_datasets = {}\n",
    "    strategy_b_datasets = {}\n",
    "    \n",
    "    print(f\"\\n🔍 DATASET COMPATIBILITY ANALYSIS:\")\n",
    "    \n",
    "    for name, df in datasets_dict.items():\n",
    "        if 'date' not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        min_date = df['date'].min()\n",
    "        max_date = df['date'].max()\n",
    "        \n",
    "        # Check Strategy A compatibility (2022-2024) - ANY overlap with period\n",
    "        strategy_a_compatible = (max_date >= pd.Timestamp(FULL_RANGE_START) and \n",
    "                                min_date <= pd.Timestamp(FULL_RANGE_END))\n",
    "        \n",
    "        # Check Strategy B compatibility (2022-2023) - ANY overlap with period  \n",
    "        strategy_b_compatible = (max_date >= pd.Timestamp(COMPLETE_RANGE_START) and \n",
    "                                min_date <= pd.Timestamp(COMPLETE_RANGE_END))\n",
    "        \n",
    "        print(f\"  {name}:\")\n",
    "        print(f\"    Range: {min_date.date()} to {max_date.date()}\")\n",
    "        print(f\"    Strategy A (2022-2024): {'✅' if strategy_a_compatible else '❌'}\")\n",
    "        print(f\"    Strategy B (2022-2023): {'✅' if strategy_b_compatible else '❌'}\")\n",
    "        \n",
    "        if strategy_a_compatible:\n",
    "            strategy_a_datasets[name] = df\n",
    "        if strategy_b_compatible:\n",
    "            strategy_b_datasets[name] = df\n",
    "    \n",
    "    print(f\"\\n📋 FINAL DATASET COMPOSITIONS:\")\n",
    "    print(f\"  Strategy A: {len(strategy_a_datasets)} datasets - {list(strategy_a_datasets.keys())}\")\n",
    "    print(f\"  Strategy B: {len(strategy_b_datasets)} datasets - {list(strategy_b_datasets.keys())}\")\n",
    "    \n",
    "    return {\n",
    "        'strategy_a': {\n",
    "            'datasets': strategy_a_datasets,\n",
    "            'date_range': (FULL_RANGE_START, FULL_RANGE_END),\n",
    "            'name': 'Full Range (2022-2024)'\n",
    "        },\n",
    "        'strategy_b': {\n",
    "            'datasets': strategy_b_datasets,\n",
    "            'date_range': (COMPLETE_RANGE_START, COMPLETE_RANGE_END),\n",
    "            'name': 'Complete Coverage (2022-2023)'\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Analyze strategies\n",
    "strategies = analyze_dataset_strategies(preprocessed_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807ee408",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Step 3: Create Unified Dataset Function\n",
    "def create_unified_dataset_strategy(datasets_dict, date_range, strategy_name):\n",
    "    \"\"\"\n",
    "    Create a unified dataset for a specific strategy\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔗 CREATING UNIFIED DATASET: {strategy_name}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    start_date, end_date = date_range\n",
    "    print(f\"📅 Date range: {start_date} to {end_date}\")\n",
    "    print(f\"📊 Datasets: {len(datasets_dict)}\")\n",
    "    \n",
    "    # Choose base dataset (sales - most complete)\n",
    "    if 'sales' not in datasets_dict:\n",
    "        print(\"❌ Sales dataset not found!\")\n",
    "        return None\n",
    "    \n",
    "    # Filter base dataset to date range\n",
    "    base_df = datasets_dict['sales'].copy()\n",
    "    base_df = base_df[(base_df['date'] >= start_date) & (base_df['date'] <= end_date)]\n",
    "    \n",
    "    print(f\"📅 Base dataset (sales): {base_df.shape}\")\n",
    "    print(f\"   Date range: {base_df['date'].min().date()} to {base_df['date'].max().date()}\")\n",
    "    \n",
    "    unified_df = base_df.copy()\n",
    "    \n",
    "    # Define time features to avoid duplication\n",
    "    time_features = ['date', 'year', 'month', 'dayofyear', 'week', 'quarter',\n",
    "                    'month_sin', 'month_cos', 'week_sin', 'week_cos', \n",
    "                    'season', 'holiday_period', 'is_month_end']\n",
    "    \n",
    "    # Merge other datasets\n",
    "    merge_summary = {}\n",
    "    \n",
    "    for dataset_name, df in datasets_dict.items():\n",
    "        if dataset_name == 'sales':\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n  🔄 Merging {dataset_name}...\")\n",
    "        \n",
    "        # Filter to date range\n",
    "        merge_df = df.copy()\n",
    "        merge_df = merge_df[(merge_df['date'] >= start_date) & (merge_df['date'] <= end_date)]\n",
    "        \n",
    "        # Identify columns to rename (business columns only)\n",
    "        business_columns = [col for col in merge_df.columns if col not in time_features]\n",
    "        \n",
    "        # Add dataset prefix to business columns to avoid conflicts\n",
    "        rename_dict = {col: f\"{dataset_name}_{col}\" for col in business_columns}\n",
    "        merge_df = merge_df.rename(columns=rename_dict)\n",
    "        \n",
    "        print(f\"    Filtered shape: {merge_df.shape}\")\n",
    "        print(f\"    Renamed {len(business_columns)} business columns\")\n",
    "        \n",
    "        # Merge on date\n",
    "        before_shape = unified_df.shape\n",
    "        unified_df = unified_df.merge(merge_df, on='date', how='left')\n",
    "        after_shape = unified_df.shape\n",
    "        \n",
    "        # Remove duplicate time features (keep only from base dataset)\n",
    "        duplicate_time_cols = [col for col in unified_df.columns \n",
    "                              if col.endswith('_x') or col.endswith('_y')]\n",
    "        \n",
    "        if duplicate_time_cols:\n",
    "            # Keep the original columns (without suffix) and drop duplicates\n",
    "            cols_to_drop = [col for col in duplicate_time_cols if col.endswith('_y')]\n",
    "            cols_to_rename = {col: col.replace('_x', '') for col in duplicate_time_cols if col.endswith('_x')}\n",
    "            \n",
    "            unified_df = unified_df.drop(columns=cols_to_drop)\n",
    "            unified_df = unified_df.rename(columns=cols_to_rename)\n",
    "            \n",
    "            print(f\"    Removed {len(cols_to_drop)} duplicate time features\")\n",
    "        \n",
    "        # Calculate merge statistics\n",
    "        new_columns = after_shape[1] - before_shape[1] - len(duplicate_time_cols)\n",
    "        records_with_data = unified_df[f\"{dataset_name}_{business_columns[0]}\"].notna().sum() if business_columns else 0\n",
    "        \n",
    "        merge_summary[dataset_name] = {\n",
    "            'columns_added': new_columns,\n",
    "            'records_with_data': records_with_data,\n",
    "            'coverage_pct': (records_with_data / len(unified_df)) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"    Shape: {before_shape} → {unified_df.shape}\")\n",
    "        print(f\"    Data coverage: {records_with_data}/{len(unified_df)} ({merge_summary[dataset_name]['coverage_pct']:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n✅ UNIFIED DATASET CREATED: {strategy_name}\")\n",
    "    print(f\"   Final shape: {unified_df.shape}\")\n",
    "    print(f\"   Date range: {unified_df['date'].min().date()} to {unified_df['date'].max().date()}\")\n",
    "    \n",
    "    return unified_df, merge_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f78857",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 CREATING BOTH STRATEGIC DATASETS\n",
      "============================================================\n",
      "\n",
      "🔗 CREATING UNIFIED DATASET: Full Range (2022-2024)\n",
      "==================================================\n",
      "📅 Date range: 2022-01-03 to 2024-12-23\n",
      "📊 Datasets: 10\n",
      "📅 Base dataset (sales): (156, 14)\n",
      "   Date range: 2022-01-03 to 2024-12-23\n",
      "\n",
      "  🔄 Merging email...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 1 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 14) → (156, 15)\n",
      "    Data coverage: 104/156 (66.7%)\n",
      "\n",
      "  🔄 Merging search...\n",
      "    Filtered shape: (156, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 15) → (156, 17)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  🔄 Merging tv_branding...\n",
      "    Filtered shape: (156, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 17) → (156, 19)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  🔄 Merging social...\n",
      "    Filtered shape: (156, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 19) → (156, 21)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  🔄 Merging ooh...\n",
      "    Filtered shape: (156, 14)\n",
      "    Renamed 1 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 21) → (156, 22)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  🔄 Merging promo...\n",
      "    Filtered shape: (47, 14)\n",
      "    Renamed 1 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 22) → (156, 23)\n",
      "    Data coverage: 47/156 (30.1%)\n",
      "\n",
      "  🔄 Merging radio_national...\n",
      "    Filtered shape: (156, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 23) → (156, 25)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  🔄 Merging radio_local...\n",
      "    Filtered shape: (156, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 25) → (156, 27)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  🔄 Merging tv_promo...\n",
      "    Filtered shape: (156, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (156, 27) → (156, 29)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "✅ UNIFIED DATASET CREATED: Full Range (2022-2024)\n",
      "   Final shape: (156, 29)\n",
      "   Date range: 2022-01-03 to 2024-12-23\n",
      "\n",
      "🔗 CREATING UNIFIED DATASET: Complete Coverage (2022-2023)\n",
      "==================================================\n",
      "📅 Date range: 2022-01-03 to 2023-12-25\n",
      "📊 Datasets: 10\n",
      "📅 Base dataset (sales): (104, 14)\n",
      "   Date range: 2022-01-03 to 2023-12-25\n",
      "\n",
      "  🔄 Merging email...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 1 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 14) → (104, 15)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  🔄 Merging search...\n",
      "    Filtered shape: (104, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 15) → (104, 17)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  🔄 Merging tv_branding...\n",
      "    Filtered shape: (104, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 17) → (104, 19)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  🔄 Merging social...\n",
      "    Filtered shape: (104, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 19) → (104, 21)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  🔄 Merging ooh...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 1 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 21) → (104, 22)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  🔄 Merging promo...\n",
      "    Filtered shape: (30, 14)\n",
      "    Renamed 1 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 22) → (104, 23)\n",
      "    Data coverage: 30/104 (28.8%)\n",
      "\n",
      "  🔄 Merging radio_national...\n",
      "    Filtered shape: (104, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 23) → (104, 25)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  🔄 Merging radio_local...\n",
      "    Filtered shape: (104, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 25) → (104, 27)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  🔄 Merging tv_promo...\n",
      "    Filtered shape: (104, 15)\n",
      "    Renamed 2 business columns\n",
      "    Removed 12 duplicate time features\n",
      "    Shape: (104, 27) → (104, 29)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "✅ UNIFIED DATASET CREATED: Complete Coverage (2022-2023)\n",
      "   Final shape: (104, 29)\n",
      "   Date range: 2022-01-03 to 2023-12-25\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create Both Strategic Datasets\n",
    "print(f\"\\n🚀 CREATING BOTH STRATEGIC DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "unified_datasets = {}\n",
    "merge_summaries = {}\n",
    "\n",
    "for strategy_key, strategy_info in strategies.items():\n",
    "    strategy_name = strategy_info['name']\n",
    "    datasets = strategy_info['datasets']\n",
    "    date_range = strategy_info['date_range']\n",
    "    \n",
    "    unified_df, merge_summary = create_unified_dataset_strategy(\n",
    "        datasets, date_range, strategy_name\n",
    "    )\n",
    "    \n",
    "    unified_datasets[strategy_key] = unified_df\n",
    "    merge_summaries[strategy_key] = merge_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e325d455",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 STRATEGIC COMPARISON\n",
      "==================================================\n",
      "\n",
      "🎯 FULL RANGE (2022-2024):\n",
      "   📅 Period: 2022-01-03 to 2024-12-23\n",
      "   📊 Shape: (156, 29)\n",
      "   📈 Weeks: 156\n",
      "   📺 Channels: 10\n",
      "   🔧 Features: 29\n",
      "   ✅ Completeness: 96.3%\n",
      "   📋 Channels included:\n",
      "     1. sales\n",
      "     2. email\n",
      "     3. search\n",
      "     4. tv_branding\n",
      "     5. social\n",
      "     6. ooh\n",
      "     7. promo\n",
      "     8. radio_national\n",
      "     9. radio_local\n",
      "     10. tv_promo\n",
      "\n",
      "🎯 COMPLETE COVERAGE (2022-2023):\n",
      "   📅 Period: 2022-01-03 to 2023-12-25\n",
      "   📊 Shape: (104, 29)\n",
      "   📈 Weeks: 104\n",
      "   📺 Channels: 10\n",
      "   🔧 Features: 29\n",
      "   ✅ Completeness: 97.5%\n",
      "   📋 Channels included:\n",
      "     1. sales\n",
      "     2. email\n",
      "     3. search\n",
      "     4. tv_branding\n",
      "     5. social\n",
      "     6. ooh\n",
      "     7. promo\n",
      "     8. radio_national\n",
      "     9. radio_local\n",
      "     10. tv_promo\n",
      "\n",
      "📋 COMPARISON SUMMARY:\n",
      "                     Strategy               Date Range  Weeks  Channels  Features Completeness     Shape\n",
      "       Full Range (2022-2024) 2022-01-03 to 2024-12-23    156        10        29        96.3% (156, 29)\n",
      "Complete Coverage (2022-2023) 2022-01-03 to 2023-12-25    104        10        29        97.5% (104, 29)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Compare the Two Strategies\n",
    "def compare_strategies(unified_datasets, merge_summaries, strategies):\n",
    "    \"\"\"\n",
    "    Compare the two strategic approaches\n",
    "    \"\"\"\n",
    "    print(f\"\\n📊 STRATEGIC COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for strategy_key, unified_df in unified_datasets.items():\n",
    "        strategy_info = strategies[strategy_key]\n",
    "        merge_summary = merge_summaries[strategy_key]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_channels = len(merge_summary) + 1  # +1 for sales (base)\n",
    "        total_weeks = len(unified_df)\n",
    "        total_features = unified_df.shape[1]\n",
    "        \n",
    "        # Calculate data completeness\n",
    "        non_date_cols = [col for col in unified_df.columns if col != 'date']\n",
    "        completeness = (unified_df[non_date_cols].notna().sum().sum() / \n",
    "                       (len(unified_df) * len(non_date_cols))) * 100\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Strategy': strategy_info['name'],\n",
    "            'Date Range': f\"{strategy_info['date_range'][0]} to {strategy_info['date_range'][1]}\",\n",
    "            'Weeks': total_weeks,\n",
    "            'Channels': total_channels,\n",
    "            'Features': total_features,\n",
    "            'Completeness': f\"{completeness:.1f}%\",\n",
    "            'Shape': unified_df.shape\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n🎯 {strategy_info['name'].upper()}:\")\n",
    "        print(f\"   📅 Period: {strategy_info['date_range'][0]} to {strategy_info['date_range'][1]}\")\n",
    "        print(f\"   📊 Shape: {unified_df.shape}\")\n",
    "        print(f\"   📈 Weeks: {total_weeks}\")\n",
    "        print(f\"   📺 Channels: {total_channels}\")\n",
    "        print(f\"   🔧 Features: {total_features}\")\n",
    "        print(f\"   ✅ Completeness: {completeness:.1f}%\")\n",
    "        \n",
    "        # Channel breakdown\n",
    "        print(f\"   📋 Channels included:\")\n",
    "        channels = ['sales'] + list(merge_summary.keys())\n",
    "        for i, channel in enumerate(channels, 1):\n",
    "            print(f\"     {i}. {channel}\")\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(f\"\\n📋 COMPARISON SUMMARY:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Compare strategies\n",
    "comparison_summary = compare_strategies(unified_datasets, merge_summaries, strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec366e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 SAVING BOTH UNIFIED DATASETS\n",
      "========================================\n",
      "  ✅ Saved: unified_dataset_full_range_2022_2024.csv\n",
      "     Full Range (2022-2024, 9 channels, 156 weeks)\n",
      "     Shape: (156, 29)\n",
      "  ✅ Saved: unified_dataset_complete_coverage_2022_2023.csv\n",
      "     Complete Coverage (2022-2023, 10 channels, 104 weeks)\n",
      "     Shape: (104, 29)\n",
      "  ✅ Saved: dual_unification_report.json\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Save Both Datasets\n",
    "def save_unified_datasets(unified_datasets, strategies, merge_summaries):\n",
    "    \"\"\"\n",
    "    Save both unified datasets with descriptive names\n",
    "    \"\"\"\n",
    "    print(f\"\\n💾 SAVING BOTH UNIFIED DATASETS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    processed_dir = '../data/processed'\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    saved_files = {}\n",
    "    \n",
    "    for strategy_key, unified_df in unified_datasets.items():\n",
    "        strategy_info = strategies[strategy_key]\n",
    "        \n",
    "        # Create descriptive filename\n",
    "        if strategy_key == 'strategy_a':\n",
    "            filename = \"unified_dataset_full_range_2022_2024.csv\"\n",
    "            description = \"Full Range (2022-2024, 9 channels, 156 weeks)\"\n",
    "        else:\n",
    "            filename = \"unified_dataset_complete_coverage_2022_2023.csv\"\n",
    "            description = \"Complete Coverage (2022-2023, 10 channels, 104 weeks)\"\n",
    "        \n",
    "        # Save dataset\n",
    "        file_path = os.path.join(processed_dir, filename)\n",
    "        unified_df.to_csv(file_path, index=False)\n",
    "        \n",
    "        saved_files[strategy_key] = {\n",
    "            'filename': filename,\n",
    "            'path': file_path,\n",
    "            'description': description,\n",
    "            'shape': unified_df.shape\n",
    "        }\n",
    "        \n",
    "        print(f\"  ✅ Saved: {filename}\")\n",
    "        print(f\"     {description}\")\n",
    "        print(f\"     Shape: {unified_df.shape}\")\n",
    "    \n",
    "    # Save comparison report\n",
    "    import json\n",
    "    \n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, pd.Timestamp):\n",
    "            return obj.isoformat()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: convert_numpy(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [convert_numpy(item) for item in obj]\n",
    "        elif hasattr(obj, 'item'):\n",
    "            return obj.item()\n",
    "        return obj\n",
    "    \n",
    "    dual_report = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'strategy_comparison': {\n",
    "            'strategy_a_full_range': {\n",
    "                'description': 'Full Range (2022-2024)',\n",
    "                'date_range': strategies['strategy_a']['date_range'],\n",
    "                'shape': unified_datasets['strategy_a'].shape,\n",
    "                'channels': len(merge_summaries['strategy_a']) + 1,\n",
    "                'filename': saved_files['strategy_a']['filename']\n",
    "            },\n",
    "            'strategy_b_complete': {\n",
    "                'description': 'Complete Coverage (2022-2023)',\n",
    "                'date_range': strategies['strategy_b']['date_range'],\n",
    "                'shape': unified_datasets['strategy_b'].shape,\n",
    "                'channels': len(merge_summaries['strategy_b']) + 1,\n",
    "                'filename': saved_files['strategy_b']['filename']\n",
    "            }\n",
    "        },\n",
    "        'merge_summaries': convert_numpy(merge_summaries),\n",
    "        'recommendation': {\n",
    "            'approach': 'Test both strategies in parallel',\n",
    "            'strategy_a_pros': ['More recent data', 'Longer time series', 'Better trend analysis'],\n",
    "            'strategy_a_cons': ['Missing email channel', 'Incomplete attribution'],\n",
    "            'strategy_b_pros': ['Complete channel coverage', 'Full attribution', 'Channel interactions'],\n",
    "            'strategy_b_cons': ['Less recent data', 'Shorter time series']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    report_path = os.path.join(processed_dir, \"dual_unification_report.json\")\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(dual_report, f, indent=2)\n",
    "    \n",
    "    print(f\"  ✅ Saved: dual_unification_report.json\")\n",
    "    \n",
    "    return saved_files, dual_report\n",
    "\n",
    "# Save both datasets\n",
    "saved_files, dual_report = save_unified_datasets(unified_datasets, strategies, merge_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3241656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 STRATEGIC RECOMMENDATIONS\n",
      "==================================================\n",
      "\n",
      "✅ BOTH DATASETS SUCCESSFULLY CREATED!\n",
      "\n",
      "📊 DATASET A - FULL RANGE:\n",
      "   📁 File: unified_dataset_full_range_2022_2024.csv\n",
      "   📈 Full Range (2022-2024, 9 channels, 156 weeks)\n",
      "   🎯 Best for: Trend analysis, recent performance, forecasting\n",
      "   ⚠️  Limitation: Missing email channel attribution\n",
      "\n",
      "📊 DATASET B - COMPLETE COVERAGE:\n",
      "   📁 File: unified_dataset_complete_coverage_2022_2023.csv\n",
      "   📈 Complete Coverage (2022-2023, 10 channels, 104 weeks)\n",
      "   🎯 Best for: Full attribution, channel interactions, ROI optimization\n",
      "   ⚠️  Limitation: Less recent data (missing 2024)\n",
      "\n",
      "🚀 NEXT STEPS - PARALLEL MMM DEVELOPMENT:\n",
      "   1. 📊 Run EDA on both datasets\n",
      "   2. 🤖 Develop identical MMM pipelines for both\n",
      "   3. 📈 Compare model performance and insights\n",
      "   4. 💰 Evaluate attribution accuracy and ROI insights\n",
      "   5. 🎯 Make data-driven decision on final approach\n",
      "\n",
      "💡 RECOMMENDATION:\n",
      "   Start with Dataset B (Complete Coverage) for initial MMM\n",
      "   Use Dataset A (Full Range) for trend validation\n",
      "   This gives you both complete attribution AND recent trends!\n",
      "\n",
      "✅ DUAL UNIFICATION COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Final Recommendations\n",
    "print(f\"\\n🎯 STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n✅ BOTH DATASETS SUCCESSFULLY CREATED!\")\n",
    "\n",
    "print(f\"\\n📊 DATASET A - FULL RANGE:\")\n",
    "print(f\"   📁 File: {saved_files['strategy_a']['filename']}\")\n",
    "print(f\"   📈 {saved_files['strategy_a']['description']}\")\n",
    "print(f\"   🎯 Best for: Trend analysis, recent performance, forecasting\")\n",
    "print(f\"   ⚠️  Limitation: Missing email channel attribution\")\n",
    "\n",
    "print(f\"\\n📊 DATASET B - COMPLETE COVERAGE:\")\n",
    "print(f\"   📁 File: {saved_files['strategy_b']['filename']}\")\n",
    "print(f\"   📈 {saved_files['strategy_b']['description']}\")\n",
    "print(f\"   🎯 Best for: Full attribution, channel interactions, ROI optimization\")\n",
    "print(f\"   ⚠️  Limitation: Less recent data (missing 2024)\")\n",
    "\n",
    "print(f\"\\n🚀 NEXT STEPS - PARALLEL MMM DEVELOPMENT:\")\n",
    "print(f\"   1. 📊 Run EDA on both datasets\")\n",
    "print(f\"   2. 🤖 Develop identical MMM pipelines for both\")\n",
    "print(f\"   3. 📈 Compare model performance and insights\")\n",
    "print(f\"   4. 💰 Evaluate attribution accuracy and ROI insights\")\n",
    "print(f\"   5. 🎯 Make data-driven decision on final approach\")\n",
    "\n",
    "print(f\"\\n💡 RECOMMENDATION:\")\n",
    "print(f\"   Start with Dataset B (Complete Coverage) for initial MMM\")\n",
    "print(f\"   Use Dataset A (Full Range) for trend validation\")\n",
    "print(f\"   This gives you both complete attribution AND recent trends!\")\n",
    "\n",
    "print(f\"\\n✅ DUAL UNIFICATION COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ccd08d",
   "metadata": {},
   "source": [
    "## Dual Unification Strategy Complete! 🎉\n",
    "\n",
    "### 🎯 **Strategic Approach Implemented:**\n",
    "\n",
    "#### **Dataset A - Full Range (2022-2024):**\n",
    "- **Period**: 156 weeks of recent data\n",
    "- **Channels**: 9 (excludes email)\n",
    "- **Strength**: Maximum data volume, recent trends\n",
    "- **Use Case**: Trend analysis, forecasting, recent performance\n",
    "\n",
    "#### **Dataset B - Complete Coverage (2022-2023):**\n",
    "- **Period**: 104 weeks of complete data\n",
    "- **Channels**: 10 (includes all channels)\n",
    "- **Strength**: Full attribution modeling\n",
    "- **Use Case**: Channel interactions, ROI optimization\n",
    "\n",
    "### 📊 **Files Created:**\n",
    "- `unified_dataset_full_range_2022_2024.csv`\n",
    "- `unified_dataset_complete_coverage_2022_2023.csv`\n",
    "- `dual_unification_report.json`\n",
    "\n",
    "### 🚀 **Next Phase:**\n",
    "**Parallel MMM Development** - Run identical modeling pipelines on both datasets to determine which approach provides better business insights!\n",
    "\n",
    "**This strategic approach ensures we make data-driven decisions about our modeling strategy.** 📈 "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
