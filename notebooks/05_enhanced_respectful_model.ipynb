{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 05_ENHANCED_RESPECTFUL_MODEL - MMM Analysis\n",
        "\n",
        "**Media Mix Modeling Component**\n",
        "\n",
        "**Research Team**: Data Science MMM Development  \n",
        "**Project**: Ice Cream Company Media Mix Modeling  \n",
        "**Objective**: Advance MMM model development\n",
        "\n",
        "## \ud83d\udd2c Research Methodology\n",
        "\n",
        "**Key Mathematical Formulations:**\n",
        "- Analysis specific formulas documented inline\n",
        "\n",
        "**Quality Standards:**\n",
        "- Temporal validation (no data leakage)\n",
        "- Statistical significance testing\n",
        "- Business logic validation\n",
        "- Reproducible analysis\n",
        "\n",
        "**Report Documentation**: All analyses documented for stakeholder reporting\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 05 - Enhanced Respectful MMM Model\n",
        "\n",
        "**Research Philosophy**: \"If they spend money on it, there's a business reason\"\n",
        "**Goal**: Improve performance while respecting ALL media channel investments\n",
        "**Team**: Data Science Research Team - Building on 04 Baseline\n",
        "\n",
        "## \ud83c\udfaf Research Enhancement Strategy\n",
        "\n",
        "1. **Intelligent Data Preprocessing**: Business-informed missing value handling\n",
        "2. **Advanced Adstock Modeling**: Channel-specific carryover patterns  \n",
        "3. **Interaction Effects**: Capture TV+Radio, Search+Social synergies\n",
        "4. **Regularization Optimization**: Time series cross-validation\n",
        "5. **Comprehensive Validation**: Better performance measurement\n",
        "\n",
        "## \ud83c\udfe2 Business Principle\n",
        "**RESPECT ALL 7 MEDIA CHANNELS** - Every investment has strategic rationale\n",
        "\n",
        "## \ud83d\udcca Enhancement Hypothesis\n",
        "04 Baseline achieved **45.1% Test R\u00b2** - can we improve while keeping all channels?\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import Ridge, RidgeCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"\ud83e\udd1d 05 - ENHANCED RESPECTFUL MMM MODEL\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\ud83d\udcca Research Goal: Improve performance while respecting ALL media investments\")\n",
        "print(\"\ud83d\udcbc Philosophy: Every channel has strategic business rationale\")\n",
        "print(\"\ud83c\udfaf Target: Beat 04 Baseline (45.1% Test R\u00b2) keeping all 7 channels\")\n",
        "\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (16, 10)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "print(f\"\\n\ud83d\udcc1 LOADING DATA\")\n",
        "print(\"=\" * 30)\n",
        "\n",
        "train_data = pd.read_csv('../data/mmm_ready/consistent_channels_train_set.csv')\n",
        "test_data = pd.read_csv('../data/mmm_ready/consistent_channels_test_set.csv')\n",
        "\n",
        "train_data['date'] = pd.to_datetime(train_data['date'])\n",
        "test_data['date'] = pd.to_datetime(test_data['date'])\n",
        "\n",
        "print(f\"\u2705 Training: {train_data.shape[0]} weeks, Test: {test_data.shape[0]} weeks\")\n",
        "\n",
        "# ALL 7 media channels - KEEP THEM ALL\n",
        "media_channels = [\n",
        "    'search_cost', 'tv_branding_tv_branding_cost', 'social_costs',\n",
        "    'ooh_ooh_spend', 'radio_national_radio_national_cost',\n",
        "    'radio_local_radio_local_cost', 'tv_promo_tv_promo_cost'\n",
        "]\n",
        "\n",
        "control_variables = [\n",
        "    'month_sin', 'month_cos', 'week_sin', 'week_cos', 'holiday_period',\n",
        "    'weather_temperature_mean', 'weather_sunshine_duration', 'promo_promotion_type'\n",
        "]\n",
        "\n",
        "print(f\"\\n\ud83d\udcca KEEPING ALL MEDIA CHANNELS:\")\n",
        "for i, channel in enumerate(media_channels, 1):\n",
        "    avg_spend = train_data[channel].fillna(0).mean()\n",
        "    print(f\"   {i}. {channel}: ${avg_spend:,.0f}/week avg\")\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENHANCEMENT 1: Intelligent Missing Value Handling\n",
        "print(f\"\\n\ud83e\udde0 ENHANCEMENT 1: INTELLIGENT MISSING VALUE HANDLING\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "def smart_missing_value_handling(data, media_cols, control_cols):\n",
        "    \"\"\"Handle missing values more intelligently\"\"\"\n",
        "    data_clean = data.copy()\n",
        "    \n",
        "    print(f\"\ud83d\udd0d Analyzing missing values:\")\n",
        "    \n",
        "    # Media channels: Use forward fill + interpolation (spending often continues)\n",
        "    for channel in media_cols:\n",
        "        if channel in data.columns:\n",
        "            missing_count = data[channel].isnull().sum()\n",
        "            if missing_count > 0:\n",
        "                print(f\"   {channel}: {missing_count} missing values\")\n",
        "                # Forward fill first (spending continues), then interpolate, then fill with 0\n",
        "                data_clean[channel] = data[channel].fillna(method='ffill').interpolate().fillna(0)\n",
        "    \n",
        "    # Control variables: Use more sophisticated imputation\n",
        "    for col in control_cols:\n",
        "        if col in data.columns:\n",
        "            missing_count = data[col].isnull().sum()\n",
        "            if missing_count > 0:\n",
        "                print(f\"   {col}: {missing_count} missing values\")\n",
        "                if col == 'promo_promotion_type':\n",
        "                    # Promotional types: use mode (most common type)\n",
        "                    mode_val = data[col].mode().iloc[0] if not data[col].mode().empty else 0\n",
        "                    data_clean[col] = data[col].fillna(mode_val)\n",
        "                elif 'weather' in col:\n",
        "                    # Weather: use seasonal interpolation\n",
        "                    data_clean[col] = data[col].interpolate(method='time').fillna(data[col].median())\n",
        "                else:\n",
        "                    # Other controls: median imputation\n",
        "                    data_clean[col] = data[col].fillna(data[col].median())\n",
        "    \n",
        "    return data_clean\n",
        "\n",
        "# Apply intelligent missing value handling\n",
        "train_clean = smart_missing_value_handling(train_data, media_channels, control_variables)\n",
        "test_clean = smart_missing_value_handling(test_data, media_channels, control_variables)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENHANCEMENT 2: Advanced Adstock with Multiple Decay Patterns\n",
        "print(f\"\\n\ud83d\udcc8 ENHANCEMENT 2: ADVANCED ADSTOCK MODELING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def apply_advanced_adstock(x, decay_rate, conc_param=1.0):\n",
        "    \"\"\"Apply adstock with concentration parameter for more flexible decay\"\"\"\n",
        "    adstocked = np.zeros_like(x)\n",
        "    adstocked[0] = x[0] if not np.isnan(x[0]) else 0\n",
        "    \n",
        "    for i in range(1, len(x)):\n",
        "        current_spend = x[i] if not np.isnan(x[i]) else 0\n",
        "        # Apply concentration parameter for different decay shapes\n",
        "        decay_effect = decay_rate ** conc_param\n",
        "        adstocked[i] = current_spend + decay_effect * adstocked[i-1]\n",
        "    \n",
        "    return adstocked\n",
        "\n",
        "# Enhanced channel-specific decay rates with business logic\n",
        "enhanced_decay_rates = {\n",
        "    'search_cost': {'decay': 0.2, 'conc': 1.0},                          # Quick decay, immediate\n",
        "    'tv_branding_tv_branding_cost': {'decay': 0.7, 'conc': 0.8},         # Long decay, gradual\n",
        "    'social_costs': {'decay': 0.3, 'conc': 1.2},                         # Medium decay, concentrated\n",
        "    'ooh_ooh_spend': {'decay': 0.6, 'conc': 0.9},                        # Long decay, outdoor visibility\n",
        "    'radio_national_radio_national_cost': {'decay': 0.5, 'conc': 1.0},   # Medium decay, broad reach\n",
        "    'radio_local_radio_local_cost': {'decay': 0.4, 'conc': 1.1},         # Shorter decay, local\n",
        "    'tv_promo_tv_promo_cost': {'decay': 0.4, 'conc': 1.3}                # Medium decay, promotional\n",
        "}\n",
        "\n",
        "def transform_media_advanced_adstock(data, media_cols):\n",
        "    \"\"\"Apply advanced adstock to all media channels\"\"\"\n",
        "    data_transformed = data.copy()\n",
        "    \n",
        "    print(f\"\ud83d\udd04 Applying advanced adstock to ALL channels:\")\n",
        "    for channel in media_cols:\n",
        "        if channel in data.columns:\n",
        "            params = enhanced_decay_rates.get(channel, {'decay': 0.4, 'conc': 1.0})\n",
        "            clean_spend = data[channel].fillna(0)\n",
        "            \n",
        "            # Apply advanced adstock\n",
        "            adstocked = apply_advanced_adstock(clean_spend.values, \n",
        "                                             params['decay'], \n",
        "                                             params['conc'])\n",
        "            \n",
        "            new_col = f\"{channel}_adstock\"\n",
        "            data_transformed[new_col] = adstocked\n",
        "            \n",
        "            # Calculate impact\n",
        "            original_sum = clean_spend.sum()\n",
        "            adstock_sum = adstocked.sum()\n",
        "            lift = (adstock_sum - original_sum) / original_sum * 100 if original_sum > 0 else 0\n",
        "            \n",
        "            print(f\"   \u2705 {channel}:\")\n",
        "            print(f\"      Decay: {params['decay']:.1f}, Concentration: {params['conc']:.1f}\")\n",
        "            print(f\"      Adstock lift: +{lift:.1f}%\")\n",
        "    \n",
        "    return data_transformed\n",
        "\n",
        "# Apply advanced adstock\n",
        "train_adstock = transform_media_advanced_adstock(train_clean, media_channels)\n",
        "test_adstock = transform_media_advanced_adstock(test_clean, media_channels)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENHANCEMENT 3: Create interaction terms for major channels\n",
        "print(f\"\\n\ud83e\udd1d ENHANCEMENT 3: CHANNEL INTERACTION EFFECTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def add_channel_interactions(data):\n",
        "    \"\"\"Add interaction terms for channels that might work together\"\"\"\n",
        "    data_interactions = data.copy()\n",
        "    \n",
        "    # TV channels might work together (brand + promo)\n",
        "    if 'tv_branding_tv_branding_cost_adstock' in data.columns and 'tv_promo_tv_promo_cost_adstock' in data.columns:\n",
        "        data_interactions['tv_synergy'] = (data['tv_branding_tv_branding_cost_adstock'] * \n",
        "                                         data['tv_promo_tv_promo_cost_adstock']) / 1000000  # Scale down\n",
        "        print(f\"   \u2705 Created TV synergy interaction\")\n",
        "    \n",
        "    # Radio channels might work together (national + local)\n",
        "    if 'radio_national_radio_national_cost_adstock' in data.columns and 'radio_local_radio_local_cost_adstock' in data.columns:\n",
        "        data_interactions['radio_synergy'] = (data['radio_national_radio_national_cost_adstock'] * \n",
        "                                            data['radio_local_radio_local_cost_adstock']) / 1000000  # Scale down\n",
        "        print(f\"   \u2705 Created Radio synergy interaction\")\n",
        "    \n",
        "    # Digital channels might work together (search + social)\n",
        "    if 'search_cost_adstock' in data.columns and 'social_costs_adstock' in data.columns:\n",
        "        data_interactions['digital_synergy'] = (data['search_cost_adstock'] * \n",
        "                                               data['social_costs_adstock']) / 1000000  # Scale down\n",
        "        print(f\"   \u2705 Created Digital synergy interaction\")\n",
        "    \n",
        "    return data_interactions\n",
        "\n",
        "train_with_interactions = add_channel_interactions(train_adstock)\n",
        "test_with_interactions = add_channel_interactions(test_adstock)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare feature sets - ALL MEDIA CHANNELS INCLUDED\n",
        "print(f\"\\n\ud83d\udcca PREPARING FEATURES - ALL CHANNELS INCLUDED\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Use all media channels with adstock\n",
        "media_features = [f\"{ch}_adstock\" for ch in media_channels]\n",
        "\n",
        "# Add interaction terms\n",
        "interaction_features = []\n",
        "if 'tv_synergy' in train_with_interactions.columns:\n",
        "    interaction_features.append('tv_synergy')\n",
        "if 'radio_synergy' in train_with_interactions.columns:\n",
        "    interaction_features.append('radio_synergy')\n",
        "if 'digital_synergy' in train_with_interactions.columns:\n",
        "    interaction_features.append('digital_synergy')\n",
        "\n",
        "# All features together\n",
        "all_features = media_features + control_variables + interaction_features\n",
        "\n",
        "print(f\"\ud83d\udcca Feature Summary:\")\n",
        "print(f\"   Media channels: {len(media_features)} (ALL KEPT)\")\n",
        "print(f\"   Control variables: {len(control_variables)}\")\n",
        "print(f\"   Interaction terms: {len(interaction_features)}\")\n",
        "print(f\"   Total features: {len(all_features)}\")\n",
        "\n",
        "# Create feature matrices\n",
        "X_train = train_with_interactions[all_features]\n",
        "X_test = test_with_interactions[all_features]\n",
        "y_train = train_clean['sales']\n",
        "y_test = test_clean['sales']\n",
        "\n",
        "# Check for any remaining missing values\n",
        "print(f\"\\n\ud83d\udd0d Final data quality check:\")\n",
        "train_missing = X_train.isnull().sum().sum()\n",
        "test_missing = X_test.isnull().sum().sum()\n",
        "print(f\"   Training missing values: {train_missing}\")\n",
        "print(f\"   Test missing values: {test_missing}\")\n",
        "\n",
        "if train_missing > 0 or test_missing > 0:\n",
        "    print(f\"   \ud83d\udd27 Fixing remaining missing values...\")\n",
        "    X_train = X_train.fillna(0)\n",
        "    X_test = X_test.fillna(0)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ENHANCEMENT 4: Advanced Regularization with Cross-Validation\n",
        "print(f\"\\n\u2699\ufe0f ENHANCEMENT 4: ADVANCED REGULARIZATION OPTIMIZATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\ud83d\udcca Model setup:\")\n",
        "print(f\"   Training samples: {X_train_scaled.shape[0]}\")\n",
        "print(f\"   Features: {X_train_scaled.shape[1]}\")\n",
        "print(f\"   Sample-to-feature ratio: {X_train_scaled.shape[0]/X_train_scaled.shape[1]:.1f}:1\")\n",
        "\n",
        "# Use RidgeCV for optimal alpha selection with time series CV\n",
        "print(f\"\\n\ud83d\udd04 Finding optimal regularization with time series CV...\")\n",
        "\n",
        "# Test a wide range of alphas\n",
        "alphas = [0.1, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500]\n",
        "\n",
        "# Use time series cross-validation\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "ridge_cv = RidgeCV(alphas=alphas, cv=tscv, scoring='neg_mean_squared_error')\n",
        "ridge_cv.fit(X_train_scaled, y_train)\n",
        "\n",
        "optimal_alpha = ridge_cv.alpha_\n",
        "print(f\"   \u2705 Optimal \u03b1: {optimal_alpha}\")\n",
        "\n",
        "# Fit final model\n",
        "final_model = Ridge(alpha=optimal_alpha)\n",
        "final_model.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the enhanced model\n",
        "print(f\"\\n\ud83d\udcca ENHANCED MODEL EVALUATION\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = final_model.predict(X_train_scaled)\n",
        "y_test_pred = final_model.predict(X_test_scaled)\n",
        "\n",
        "# Metrics\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "gap = train_r2 - test_r2\n",
        "\n",
        "print(f\"\ud83c\udfaf PERFORMANCE METRICS:\")\n",
        "print(f\"   Training R\u00b2: {train_r2:.3f} ({train_r2*100:.1f}%)\")\n",
        "print(f\"   Test R\u00b2: {test_r2:.3f} ({test_r2*100:.1f}%)\")\n",
        "print(f\"   Overfitting gap: {gap:.3f} ({gap*100:.1f}%)\")\n",
        "print(f\"   Test MAE: ${test_mae:,.0f}\")\n",
        "\n",
        "print(f\"\\n\ud83d\udcca RESEARCH COMPARISON WITH 04 BASELINE MODEL:\")\n",
        "baseline_test_r2 = 0.451\n",
        "baseline_gap = 0.141\n",
        "\n",
        "r2_improvement = (test_r2 - baseline_test_r2) / baseline_test_r2 * 100\n",
        "gap_improvement = (baseline_gap - gap) / baseline_gap * 100\n",
        "\n",
        "print(f\"   04 Baseline: Test R\u00b2 = 45.1%, Overfitting Gap = 14.1%\")\n",
        "print(f\"   05 Enhanced: Test R\u00b2 = {test_r2*100:.1f}%, Overfitting Gap = {gap*100:.1f}%\")\n",
        "\n",
        "print(f\"\\n\ud83c\udfaf ENHANCEMENT RESULTS:\")\n",
        "if r2_improvement > 0:\n",
        "    print(f\"   \ud83d\udcc8 R\u00b2 IMPROVEMENT: +{r2_improvement:.1f}% relative gain\")\n",
        "    print(f\"   \ud83d\udcca Absolute R\u00b2 gain: +{(test_r2 - baseline_test_r2)*100:.1f} percentage points\")\n",
        "else:\n",
        "    print(f\"   \ud83d\udcc9 R\u00b2 Change: {r2_improvement:.1f}% (needs investigation)\")\n",
        "\n",
        "if gap_improvement > 0:\n",
        "    print(f\"   \u2705 OVERFITTING REDUCTION: -{gap_improvement:.1f}% (better generalization)\")\n",
        "else:\n",
        "    print(f\"   \u26a0\ufe0f  Overfitting change: {gap_improvement:.1f}% (monitor closely)\")\n",
        "\n",
        "# Research success criteria\n",
        "print(f\"\\n\ud83c\udfaf RESEARCH SUCCESS ASSESSMENT:\")\n",
        "if test_r2 > baseline_test_r2 and gap < baseline_gap:\n",
        "    print(f\"   \ud83c\udfc6 FULL SUCCESS: Better performance + better generalization\")\n",
        "elif test_r2 > baseline_test_r2:\n",
        "    print(f\"   \u2705 PARTIAL SUCCESS: Better performance (watch overfitting)\")\n",
        "elif gap < baseline_gap:\n",
        "    print(f\"   \ud83d\udcca MIXED RESULTS: Better generalization (performance needs work)\")\n",
        "else:\n",
        "    print(f\"   \u26a0\ufe0f  NEEDS WORK: Review enhancement strategies\")\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Business insights - ALL CHANNELS INCLUDED\n",
        "print(f\"\\n\ud83d\udcbc BUSINESS INSIGHTS - ALL CHANNELS ANALYSIS\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# Feature importance\n",
        "coefficients = final_model.coef_\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': all_features,\n",
        "    'Coefficient': coefficients,\n",
        "    'Abs_Coefficient': np.abs(coefficients)\n",
        "}).sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(f\"\ud83c\udfc6 TOP 10 MOST INFLUENTIAL FEATURES:\")\n",
        "for i, row in feature_importance.head(10).iterrows():\n",
        "    coef = row['Coefficient']\n",
        "    direction = \"\ud83d\udcc8 Positive\" if coef > 0 else \"\ud83d\udcc9 Negative\"\n",
        "    feature_name = row['Feature']\n",
        "    print(f\"   {i+1}. {feature_name}: {coef:.2e} ({direction})\")\n",
        "\n",
        "# Media channel specific insights\n",
        "print(f\"\\n\ud83d\udcb0 ALL MEDIA CHANNELS - BUSINESS PERFORMANCE:\")\n",
        "media_insights = {}\n",
        "for i, feature in enumerate(all_features):\n",
        "    if any(ch in feature for ch in media_channels) and '_adstock' in feature:\n",
        "        # Extract original channel name\n",
        "        original_channel = None\n",
        "        for ch in media_channels:\n",
        "            if ch in feature:\n",
        "                original_channel = ch\n",
        "                break\n",
        "        \n",
        "        if original_channel:\n",
        "            coef_val = coefficients[i]\n",
        "            avg_spend = train_clean[original_channel].mean()\n",
        "            \n",
        "            # Determine impact level\n",
        "            abs_coef = abs(coef_val)\n",
        "            coef_std = np.std(np.abs(coefficients))\n",
        "            \n",
        "            if abs_coef > coef_std:\n",
        "                impact_level = \"\ud83d\udd25 High Impact\"\n",
        "            elif abs_coef > coef_std * 0.5:\n",
        "                impact_level = \"\u2b50 Medium Impact\"\n",
        "            else:\n",
        "                impact_level = \"\ud83d\udca1 Low Impact\"\n",
        "            \n",
        "            direction = \"Positive ROI\" if coef_val > 0 else \"Negative ROI\"\n",
        "            \n",
        "            media_insights[original_channel] = {\n",
        "                'coefficient': coef_val,\n",
        "                'avg_spend': avg_spend,\n",
        "                'impact_level': impact_level,\n",
        "                'direction': direction\n",
        "            }\n",
        "\n",
        "# Sort by absolute coefficient value\n",
        "sorted_channels = sorted(media_insights.items(), \n",
        "                        key=lambda x: abs(x[1]['coefficient']), \n",
        "                        reverse=True)\n",
        "\n",
        "for rank, (channel, info) in enumerate(sorted_channels, 1):\n",
        "    coef = info['coefficient']\n",
        "    spend = info['avg_spend']\n",
        "    impact = info['impact_level']\n",
        "    direction = info['direction']\n",
        "    \n",
        "    print(f\"\\n   {rank}. {channel}:\")\n",
        "    print(f\"      {impact} - {direction}\")\n",
        "    print(f\"      Average weekly spend: ${spend:,.0f}\")\n",
        "    print(f\"      Coefficient: {coef:.2e}\")\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VISUALIZATION: Actual vs Predicted\n",
        "print(f\"\\n\ud83d\udcca MODEL PERFORMANCE VISUALIZATION\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Plot 1: Time Series - Training Data\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(train_clean['date'], y_train, 'b-', label='Actual', linewidth=2, alpha=0.7)\n",
        "ax1.plot(train_clean['date'], y_train_pred, 'r--', label='Predicted', linewidth=2)\n",
        "ax1.set_title(f'Training Set: Actual vs Predicted\\nR\u00b2 = {train_r2:.3f}')\n",
        "ax1.set_ylabel('Sales')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Time Series - Test Data\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(test_clean['date'], y_test, 'b-', label='Actual', linewidth=2, alpha=0.7)\n",
        "ax2.plot(test_clean['date'], y_test_pred, 'r--', label='Predicted', linewidth=2)\n",
        "ax2.set_title(f'Test Set: Actual vs Predicted\\nR\u00b2 = {test_r2:.3f}')\n",
        "ax2.set_ylabel('Sales')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Scatter Plot - Training\n",
        "ax3 = axes[1, 0]\n",
        "ax3.scatter(y_train, y_train_pred, alpha=0.6, color='blue', s=30)\n",
        "min_val = min(y_train.min(), y_train_pred.min())\n",
        "max_val = max(y_train.max(), y_train_pred.max())\n",
        "ax3.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5)\n",
        "ax3.set_xlabel('Actual Sales')\n",
        "ax3.set_ylabel('Predicted Sales')\n",
        "ax3.set_title(f'Training: Actual vs Predicted\\nR\u00b2 = {train_r2:.3f}')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Scatter Plot - Test\n",
        "ax4 = axes[1, 1]\n",
        "ax4.scatter(y_test, y_test_pred, alpha=0.8, color='red', s=50)\n",
        "min_val = min(y_test.min(), y_test_pred.min())\n",
        "max_val = max(y_test.max(), y_test_pred.max())\n",
        "ax4.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5)\n",
        "ax4.set_xlabel('Actual Sales')\n",
        "ax4.set_ylabel('Predicted Sales')\n",
        "ax4.set_title(f'Test: Actual vs Predicted\\nR\u00b2 = {test_r2:.3f}')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Enhanced MMM Model Performance', fontsize=16, y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Performance summary\n",
        "print(f\"\\n\ud83c\udfaf VISUAL PERFORMANCE SUMMARY:\")\n",
        "print(f\"   \ud83d\udcc8 Training R\u00b2: {train_r2:.3f} ({train_r2*100:.1f}%)\")\n",
        "print(f\"   \ud83d\udcca Test R\u00b2: {test_r2:.3f} ({test_r2*100:.1f}%)\")\n",
        "print(f\"   \ud83d\udd0d Overfitting Gap: {gap:.3f} ({gap*100:.1f}%)\")\n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final recommendations\n",
        "print(f\"\\n\ud83c\udfaf FINAL RECOMMENDATIONS - RESPECTFUL APPROACH\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "print(f\"\u2705 WHAT WE ACHIEVED:\")\n",
        "print(f\"   \u2022 Kept ALL 7 media channels (respecting business decisions)\")\n",
        "print(f\"   \u2022 Test R\u00b2: {test_r2:.1%} (vs 45.1% original)\")\n",
        "print(f\"   \u2022 Overfitting gap: {gap:.1%} (vs 14.1% original)\")\n",
        "print(f\"   \u2022 Added channel synergy effects\")\n",
        "print(f\"   \u2022 More sophisticated adstock modeling\")\n",
        "\n",
        "print(f\"\\n\ud83d\udcbc BUSINESS INSIGHTS:\")\n",
        "print(f\"   \ud83c\udfc6 TOP PERFORMING CHANNELS:\")\n",
        "for rank, (channel, info) in enumerate(sorted_channels[:3], 1):\n",
        "    print(f\"      {rank}. {channel}: {info['impact_level']} - {info['direction']}\")\n",
        "\n",
        "if len(sorted_channels) > 3:\n",
        "    print(f\"\\n   \ud83d\udca1 OTHER CHANNELS (Still valuable!):\")\n",
        "    for rank, (channel, info) in enumerate(sorted_channels[3:], 4):\n",
        "        print(f\"      {rank}. {channel}: {info['impact_level']} - {info['direction']}\")\n",
        "\n",
        "print(f\"\\n\ud83d\ude80 NEXT STEPS:\")\n",
        "print(f\"   1. Focus budget increases on top performing channels\")\n",
        "print(f\"   2. Optimize spend levels for all channels\")\n",
        "print(f\"   3. Test channel synergies (TV, Radio, Digital combinations)\")\n",
        "print(f\"   4. Monitor performance and adjust based on results\")\n",
        "print(f\"\")\n",
        "print(f\"\ud83d\udca1 KEY INSIGHT: Every channel has a role - optimize rather than eliminate!\") \n"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}