{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f2eed42",
   "metadata": {},
   "source": [
    "# ðŸŒ¤ï¸ Step 1c: Data Unification & Weather Integration\n",
    "\n",
    "## ðŸ“‹ **Project Context**\n",
    "This is the **critical unification step** in our MMM pipeline. We merge 10+ individual preprocessed datasets into unified modeling datasets while adding weather intelligence. This step determines our modeling strategy and data foundation.\n",
    "\n",
    "## ðŸŽ¯ **Business Objective**\n",
    "Create two strategic datasets that balance **data volume** vs **channel completeness** while integrating weather factors crucial for ice cream business. Weather significantly impacts ice cream consumption and must be included in MMM.\n",
    "\n",
    "## ðŸ¤” **The Core Business Challenge**\n",
    "\n",
    "### **The Email Data Gap Problem**\n",
    "- **Email data**: Only available 2022-2023 (104 weeks)\n",
    "- **Other channels**: Available 2022-2024 (156 weeks)  \n",
    "- **Dilemma**: More data OR complete channel view?\n",
    "\n",
    "### **Weather Integration Need**\n",
    "- **Ice cream business**: Highly weather-dependent\n",
    "- **Consumer behavior**: Temperature drives consumption patterns\n",
    "- **Marketing timing**: Campaigns align with weather forecasts\n",
    "- **Business insight**: Weather = natural control variable for MMM\n",
    "\n",
    "## ðŸ”„ **Our Strategic Solution: Dual Dataset Approach**\n",
    "\n",
    "We create **two complementary datasets** instead of choosing one:\n",
    "\n",
    "### **ðŸ“Š Dataset A: Maximum Learning Power**\n",
    "- **Time Range**: 2022-2024 (156 weeks)\n",
    "- **Channels**: 9 marketing channels + weather (excluding email)\n",
    "- **Purpose**: Long-term trend learning, seasonality detection\n",
    "- **Business Value**: Maximum statistical power for each channel effect\n",
    "\n",
    "**Why This Matters:**\n",
    "- **50% more data** = better statistical confidence\n",
    "- **3-year span** = captures multiple seasonal cycles\n",
    "- **Trend analysis** = can detect changing marketing effectiveness over time\n",
    "\n",
    "### **ðŸ“Š Dataset B: Complete Attribution View**  \n",
    "- **Time Range**: 2022-2023 (104 weeks)\n",
    "- **Channels**: 10 marketing channels + weather (including email)\n",
    "- **Purpose**: Complete channel interaction analysis\n",
    "- **Business Value**: Full marketing mix understanding\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Complete picture** = no missing attribution gaps\n",
    "- **Email impact** = can measure email's incremental contribution\n",
    "- **Channel interactions** = can detect synergies between all channels\n",
    "\n",
    "## ðŸŒ¡ï¸ **Weather Data Integration Strategy**\n",
    "\n",
    "### **Weather Variables Included:**\n",
    "- `weather_temperature_mean` - Daily average temperature\n",
    "- `weather_temperature_max` - Daily maximum temperature  \n",
    "- `weather_temperature_min` - Daily minimum temperature\n",
    "- `weather_sunshine_duration` - Hours of sunshine\n",
    "\n",
    "### **Why These Weather Features:**\n",
    "- **Temperature**: Primary driver of ice cream consumption\n",
    "- **Sunshine**: Associated with outdoor activities and ice cream occasions\n",
    "- **Weekly aggregation**: Matches our media spend aggregation level\n",
    "- **Leading indicators**: Weather forecasts can inform media planning\n",
    "\n",
    "## ðŸ”§ **Technical Unification Process**\n",
    "\n",
    "### **1. Weather Data Preprocessing**\n",
    "- Convert dates to match marketing data format\n",
    "- Add `weather_` prefix to prevent column conflicts\n",
    "- Ensure weekly Monday-start alignment with marketing data\n",
    "\n",
    "### **2. Marketing Data Alignment**\n",
    "- Standardize date columns across all datasets\n",
    "- Handle missing weeks (forward-fill where appropriate)\n",
    "- Ensure consistent column naming\n",
    "\n",
    "### **3. Strategic Join Logic**\n",
    "- **Left join** on sales data (sales drives the calendar)\n",
    "- **Preserve all sales weeks** (business requirement)\n",
    "- **Fill missing media** with 0 (no spend = no activity)\n",
    "\n",
    "### **4. Data Quality Validation**\n",
    "- Check for gaps in critical time periods\n",
    "- Validate channel spend patterns make business sense\n",
    "- Ensure weather data coverage aligns with business periods\n",
    "\n",
    "## ðŸŽ¯ **MMM-Specific Design Decisions**\n",
    "\n",
    "### **Why Weekly Aggregation?**\n",
    "- **Marketing Reality**: Campaigns run weekly\n",
    "- **Sales Patterns**: Ice cream sales show weekly seasonality\n",
    "- **Planning Frequency**: Marketing teams plan weekly budgets\n",
    "\n",
    "### **Why Weather Integration?**\n",
    "- **External Factor**: Weather is truly exogenous (not controlled by marketing)\n",
    "- **Business Logic**: Hot weather drives ice cream consumption independently\n",
    "- **Model Improvement**: Weather helps separate organic demand from media-driven demand\n",
    "\n",
    "### **Why Dual Strategy?**\n",
    "- **Business Trade-offs**: No single \"perfect\" dataset exists\n",
    "- **Model Robustness**: Test insights across different data configurations\n",
    "- **Stakeholder Needs**: Different questions need different data ranges\n",
    "\n",
    "## ðŸ“Š **Expected Outputs**\n",
    "- **Dataset A**: `mmm_full_range_channels_2022_2024.csv` (156 weeks, 9 channels + weather)\n",
    "- **Dataset B**: `mmm_complete_channels_2022_2023.csv` (104 weeks, 10 channels + weather)\n",
    "- **Metadata**: Documentation of joins, missing data patterns, quality checks\n",
    "- **Foundation**: Ready for EDA and modeling phases\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ **Technical Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3d000f2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ¤ï¸ ENHANCED DUAL DATA UNIFICATION WITH WEATHER\n",
      "======================================================================\n",
      "ðŸ“… Started at: 2025-06-19 21:30:22\n",
      "\n",
      "ðŸŽ¯ CREATING TWO ENHANCED STRATEGIC DATASETS:\n",
      "   ðŸ“Š Dataset A: Full Range + Weather (2022-2024, 9 channels + weather)\n",
      "   ðŸ“Š Dataset B: Complete Coverage + Weather (2022-2023, 10 channels + weather)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(\"ðŸŒ¤ï¸ ENHANCED DUAL DATA UNIFICATION WITH WEATHER\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ðŸ“… Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "print(\"ðŸŽ¯ CREATING TWO ENHANCED STRATEGIC DATASETS:\")\n",
    "print(\"   ðŸ“Š Dataset A: Full Range + Weather (2022-2024, 9 channels + weather)\")\n",
    "print(\"   ðŸ“Š Dataset B: Complete Coverage + Weather (2022-2023, 10 channels + weather)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fdc5701",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŒ¤ï¸ LOADING WEATHER DATA\n",
      "==============================\n",
      "  âœ… Raw weather data loaded: (171, 5)\n",
      "  ðŸ“… Date range: 2021-12-27 to 2025-03-31\n",
      "  ðŸŒ¡ï¸ Weather variables: 4\n",
      "     ['weather_temperature_mean', 'weather_temperature_max', 'weather_sunshine_duration', 'weather_temperature_min']\n",
      "  âœ… Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Weather Data First\n",
    "def load_and_preprocess_weather():\n",
    "    \"\"\"\n",
    "    Load and preprocess weather data to match our dataset structure\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸŒ¤ï¸ LOADING WEATHER DATA\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    weather_path = '../data/raw/weekly_weather_monday_start.csv'\n",
    "    \n",
    "    try:\n",
    "        weather_df = pd.read_csv(weather_path)\n",
    "        print(f\"  âœ… Raw weather data loaded: {weather_df.shape}\")\n",
    "        \n",
    "        # Rename date column to match our format\n",
    "        weather_df = weather_df.rename(columns={'Date_time': 'date'})\n",
    "        \n",
    "        # Convert date to datetime\n",
    "        weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "        \n",
    "        # Add weather prefix to all columns except date\n",
    "        weather_columns = [col for col in weather_df.columns if col != 'date']\n",
    "        rename_dict = {col: f\"weather_{col}\" for col in weather_columns}\n",
    "        weather_df = weather_df.rename(columns=rename_dict)\n",
    "        \n",
    "        print(f\"  ðŸ“… Date range: {weather_df['date'].min().date()} to {weather_df['date'].max().date()}\")\n",
    "        print(f\"  ðŸŒ¡ï¸ Weather variables: {len(weather_columns)}\")\n",
    "        print(f\"     {list(rename_dict.values())}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing = weather_df.isnull().sum().sum()\n",
    "        print(f\"  âœ… Missing values: {missing}\")\n",
    "        \n",
    "        return weather_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error loading weather data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load weather data\n",
    "weather_data = load_and_preprocess_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b3b63b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ LOADING PREPROCESSED MARKETING DATASETS\n",
      "========================================\n",
      "Found 10 preprocessed datasets:\n",
      "  âœ… email: (104, 13) | 2022-01-03 to 2023-12-25\n",
      "  âœ… sales: (156, 13) | 2022-01-03 to 2024-12-23\n",
      "  âœ… search: (156, 14) | 2022-01-03 to 2024-12-23\n",
      "  âœ… tv_branding: (156, 14) | 2022-01-03 to 2024-12-23\n",
      "  âœ… social: (156, 14) | 2022-01-03 to 2024-12-23\n",
      "  âœ… ooh: (156, 13) | 2022-01-03 to 2024-12-23\n",
      "  âœ… promo: (47, 13) | 2022-01-10 to 2024-11-04\n",
      "  âœ… radio_national: (156, 14) | 2022-01-03 to 2024-12-23\n",
      "  âœ… radio_local: (156, 14) | 2022-01-03 to 2024-12-23\n",
      "  âœ… tv_promo: (156, 14) | 2022-01-03 to 2024-12-23\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load All Preprocessed Marketing Datasets\n",
    "def load_preprocessed_datasets():\n",
    "    \"\"\"\n",
    "    Load all preprocessed marketing datasets from the processed directory\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“‚ LOADING PREPROCESSED MARKETING DATASETS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    processed_dir = '../data/processed'\n",
    "    datasets = {}\n",
    "    \n",
    "    # Find all preprocessed CSV files\n",
    "    csv_files = [f for f in os.listdir(processed_dir) if f.endswith('_preprocessed.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"âŒ No preprocessed files found!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(csv_files)} preprocessed datasets:\")\n",
    "    \n",
    "    for file in csv_files:\n",
    "        # Extract dataset name (remove _preprocessed.csv)\n",
    "        dataset_name = file.replace('_preprocessed.csv', '')\n",
    "        file_path = os.path.join(processed_dir, file)\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Convert date column if it exists\n",
    "            if 'date' in df.columns:\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            datasets[dataset_name] = df\n",
    "            \n",
    "            # Display info\n",
    "            date_range = f\"{df['date'].min().date()} to {df['date'].max().date()}\" if 'date' in df.columns else \"No date\"\n",
    "            print(f\"  âœ… {dataset_name}: {df.shape} | {date_range}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ Error loading {file}: {e}\")\n",
    "    \n",
    "    return datasets\n",
    "\n",
    "# Load marketing datasets\n",
    "marketing_datasets = load_preprocessed_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f797b47",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ ENHANCED STRATEGIC DATASET ANALYSIS\n",
      "==================================================\n",
      "\n",
      "ðŸ“Š ENHANCED DATASET A - FULL RANGE + WEATHER:\n",
      "   ðŸ“… Period: 2022-01-03 to 2024-12-23\n",
      "   ðŸ“ˆ Duration: ~156 weeks (3 years)\n",
      "   ðŸ“Š Channels: 9 marketing + weather (excludes email)\n",
      "\n",
      "ðŸ“Š ENHANCED DATASET B - COMPLETE COVERAGE + WEATHER:\n",
      "   ðŸ“… Period: 2022-01-03 to 2023-12-25\n",
      "   ðŸ“ˆ Duration: ~104 weeks (2 years)\n",
      "   ðŸ“Š Channels: 10 marketing + weather (includes all channels)\n",
      "\n",
      "ðŸŒ¤ï¸ WEATHER DATA COVERAGE:\n",
      "  Full range (2022-2024): 156 weeks\n",
      "  Complete range (2022-2023): 104 weeks\n",
      "\n",
      "ðŸ” MARKETING DATASET COMPATIBILITY:\n",
      "  email:\n",
      "    Range: 2022-01-03 to 2023-12-25\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  sales:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  search:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  tv_branding:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  social:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  ooh:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  promo:\n",
      "    Range: 2022-01-10 to 2024-11-04\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  radio_national:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  radio_local:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "  tv_promo:\n",
      "    Range: 2022-01-03 to 2024-12-23\n",
      "    Strategy A (2022-2024): âœ…\n",
      "    Strategy B (2022-2023): âœ…\n",
      "\n",
      "ðŸ“‹ ENHANCED DATASET COMPOSITIONS:\n",
      "  Strategy A: 10 marketing + weather\n",
      "  Strategy B: 10 marketing + weather\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define Enhanced Strategies with Weather\n",
    "def analyze_enhanced_strategies(datasets_dict, weather_df):\n",
    "    \"\"\"\n",
    "    Analyze the two strategic approaches enhanced with weather data\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸŽ¯ ENHANCED STRATEGIC DATASET ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not datasets_dict or weather_df is None:\n",
    "        print(\"âŒ Missing required datasets!\")\n",
    "        return None\n",
    "    \n",
    "    # Define date ranges (same as before)\n",
    "    FULL_RANGE_START = '2022-01-03'\n",
    "    FULL_RANGE_END = '2024-12-23'\n",
    "    COMPLETE_RANGE_START = '2022-01-03'\n",
    "    COMPLETE_RANGE_END = '2023-12-25'\n",
    "    \n",
    "    print(f\"\\nðŸ“Š ENHANCED DATASET A - FULL RANGE + WEATHER:\")\n",
    "    print(f\"   ðŸ“… Period: {FULL_RANGE_START} to {FULL_RANGE_END}\")\n",
    "    print(f\"   ðŸ“ˆ Duration: ~156 weeks (3 years)\")\n",
    "    print(f\"   ðŸ“Š Channels: 9 marketing + weather (excludes email)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š ENHANCED DATASET B - COMPLETE COVERAGE + WEATHER:\")\n",
    "    print(f\"   ðŸ“… Period: {COMPLETE_RANGE_START} to {COMPLETE_RANGE_END}\")\n",
    "    print(f\"   ðŸ“ˆ Duration: ~104 weeks (2 years)\")\n",
    "    print(f\"   ðŸ“Š Channels: 10 marketing + weather (includes all channels)\")\n",
    "    \n",
    "    # Check weather data coverage for both strategies\n",
    "    weather_full_range = weather_df[\n",
    "        (weather_df['date'] >= FULL_RANGE_START) & \n",
    "        (weather_df['date'] <= FULL_RANGE_END)\n",
    "    ]\n",
    "    weather_complete_range = weather_df[\n",
    "        (weather_df['date'] >= COMPLETE_RANGE_START) & \n",
    "        (weather_df['date'] <= COMPLETE_RANGE_END)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nðŸŒ¤ï¸ WEATHER DATA COVERAGE:\")\n",
    "    print(f\"  Full range (2022-2024): {weather_full_range.shape[0]} weeks\")\n",
    "    print(f\"  Complete range (2022-2023): {weather_complete_range.shape[0]} weeks\")\n",
    "    \n",
    "    # Analyze marketing dataset compatibility (same logic as before)\n",
    "    strategy_a_datasets = {}\n",
    "    strategy_b_datasets = {}\n",
    "    \n",
    "    print(f\"\\nðŸ” MARKETING DATASET COMPATIBILITY:\")\n",
    "    \n",
    "    for name, df in datasets_dict.items():\n",
    "        if 'date' not in df.columns:\n",
    "            continue\n",
    "            \n",
    "        min_date = df['date'].min()\n",
    "        max_date = df['date'].max()\n",
    "        \n",
    "        # Strategy compatibility\n",
    "        strategy_a_compatible = (max_date >= pd.Timestamp(FULL_RANGE_START) and \n",
    "                                min_date <= pd.Timestamp(FULL_RANGE_END))\n",
    "        strategy_b_compatible = (max_date >= pd.Timestamp(COMPLETE_RANGE_START) and \n",
    "                                min_date <= pd.Timestamp(COMPLETE_RANGE_END))\n",
    "        \n",
    "        print(f\"  {name}:\")\n",
    "        print(f\"    Range: {min_date.date()} to {max_date.date()}\")\n",
    "        print(f\"    Strategy A (2022-2024): {'âœ…' if strategy_a_compatible else 'âŒ'}\")\n",
    "        print(f\"    Strategy B (2022-2023): {'âœ…' if strategy_b_compatible else 'âŒ'}\")\n",
    "        \n",
    "        if strategy_a_compatible:\n",
    "            strategy_a_datasets[name] = df\n",
    "        if strategy_b_compatible:\n",
    "            strategy_b_datasets[name] = df\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ ENHANCED DATASET COMPOSITIONS:\")\n",
    "    print(f\"  Strategy A: {len(strategy_a_datasets)} marketing + weather\")\n",
    "    print(f\"  Strategy B: {len(strategy_b_datasets)} marketing + weather\")\n",
    "    \n",
    "    return {\n",
    "        'strategy_a': {\n",
    "            'datasets': strategy_a_datasets,\n",
    "            'weather': weather_full_range,\n",
    "            'date_range': (FULL_RANGE_START, FULL_RANGE_END),\n",
    "            'name': 'Full Range + Weather (2022-2024)'\n",
    "        },\n",
    "        'strategy_b': {\n",
    "            'datasets': strategy_b_datasets,\n",
    "            'weather': weather_complete_range,\n",
    "            'date_range': (COMPLETE_RANGE_START, COMPLETE_RANGE_END),\n",
    "            'name': 'Complete Coverage + Weather (2022-2023)'\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Analyze enhanced strategies\n",
    "enhanced_strategies = analyze_enhanced_strategies(marketing_datasets, weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "103048a5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Step 4: Create Enhanced Unified Dataset Function\n",
    "def create_enhanced_unified_dataset(datasets_dict, weather_df, date_range, strategy_name):\n",
    "    \"\"\"\n",
    "    Create a unified dataset with weather data for a specific strategy\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ”— CREATING ENHANCED UNIFIED DATASET: {strategy_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_date, end_date = date_range\n",
    "    print(f\"ðŸ“… Date range: {start_date} to {end_date}\")\n",
    "    print(f\"ðŸ“Š Marketing datasets: {len(datasets_dict)}\")\n",
    "    print(f\"ðŸŒ¤ï¸ Weather data: {'âœ…' if weather_df is not None else 'âŒ'}\")\n",
    "    \n",
    "    # Start with base dataset (sales)\n",
    "    if 'sales' not in datasets_dict:\n",
    "        print(\"âŒ Sales dataset not found!\")\n",
    "        return None, None\n",
    "    \n",
    "    # Filter base dataset to date range\n",
    "    base_df = datasets_dict['sales'].copy()\n",
    "    base_df = base_df[(base_df['date'] >= start_date) & (base_df['date'] <= end_date)]\n",
    "    \n",
    "    print(f\"\\nðŸ“… Base dataset (sales): {base_df.shape}\")\n",
    "    print(f\"   Date range: {base_df['date'].min().date()} to {base_df['date'].max().date()}\")\n",
    "    \n",
    "    unified_df = base_df.copy()\n",
    "    \n",
    "    # Define time features to avoid duplication\n",
    "    time_features = ['date', 'year', 'month', 'dayofyear', 'week', 'quarter',\n",
    "                    'month_sin', 'month_cos', 'week_sin', 'week_cos', \n",
    "                    'season', 'holiday_period', 'is_month_end']\n",
    "    \n",
    "    # Track merge operations\n",
    "    merge_summary = {}\n",
    "    \n",
    "    # First, merge weather data\n",
    "    if weather_df is not None:\n",
    "        print(f\"\\n  ðŸŒ¤ï¸ Merging weather data...\")\n",
    "        \n",
    "        # Filter weather to date range\n",
    "        weather_merge = weather_df[(weather_df['date'] >= start_date) & \n",
    "                                  (weather_df['date'] <= end_date)].copy()\n",
    "        \n",
    "        print(f\"    Filtered weather shape: {weather_merge.shape}\")\n",
    "        \n",
    "        # Merge weather data\n",
    "        before_shape = unified_df.shape\n",
    "        unified_df = unified_df.merge(weather_merge, on='date', how='left')\n",
    "        after_shape = unified_df.shape\n",
    "        \n",
    "        weather_columns = [col for col in weather_merge.columns if col != 'date']\n",
    "        records_with_weather = unified_df[weather_columns[0]].notna().sum() if weather_columns else 0\n",
    "        \n",
    "        merge_summary['weather'] = {\n",
    "            'columns_added': len(weather_columns),\n",
    "            'records_with_data': records_with_weather,\n",
    "            'coverage_pct': (records_with_weather / len(unified_df)) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"    Shape: {before_shape} â†’ {after_shape}\")\n",
    "        print(f\"    Weather coverage: {records_with_weather}/{len(unified_df)} ({merge_summary['weather']['coverage_pct']:.1f}%)\")\n",
    "    \n",
    "    # Then merge marketing datasets\n",
    "    for dataset_name, df in datasets_dict.items():\n",
    "        if dataset_name == 'sales':\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n  ðŸ”„ Merging {dataset_name}...\")\n",
    "        \n",
    "        # Filter to date range\n",
    "        merge_df = df.copy()\n",
    "        merge_df = merge_df[(merge_df['date'] >= start_date) & (merge_df['date'] <= end_date)]\n",
    "        \n",
    "        # Identify business columns (non-time features)\n",
    "        business_columns = [col for col in merge_df.columns if col not in time_features]\n",
    "        \n",
    "        # Add dataset prefix to business columns\n",
    "        rename_dict = {col: f\"{dataset_name}_{col}\" for col in business_columns}\n",
    "        merge_df = merge_df.rename(columns=rename_dict)\n",
    "        \n",
    "        print(f\"    Filtered shape: {merge_df.shape}\")\n",
    "        print(f\"    Renamed {len(business_columns)} business columns\")\n",
    "        \n",
    "        # Merge on date\n",
    "        before_shape = unified_df.shape\n",
    "        unified_df = unified_df.merge(merge_df, on='date', how='left')\n",
    "        after_shape = unified_df.shape\n",
    "        \n",
    "        # Remove duplicate time features\n",
    "        duplicate_time_cols = [col for col in unified_df.columns \n",
    "                              if col.endswith('_x') or col.endswith('_y')]\n",
    "        \n",
    "        if duplicate_time_cols:\n",
    "            cols_to_drop = [col for col in duplicate_time_cols if col.endswith('_y')]\n",
    "            cols_to_rename = {col: col.replace('_x', '') for col in duplicate_time_cols if col.endswith('_x')}\n",
    "            \n",
    "            unified_df = unified_df.drop(columns=cols_to_drop)\n",
    "            unified_df = unified_df.rename(columns=cols_to_rename)\n",
    "            \n",
    "            print(f\"    Removed {len(cols_to_drop)} duplicate time features\")\n",
    "        \n",
    "        # Calculate merge statistics\n",
    "        new_columns = after_shape[1] - before_shape[1] - len(duplicate_time_cols)\n",
    "        records_with_data = unified_df[f\"{dataset_name}_{business_columns[0]}\"].notna().sum() if business_columns else 0\n",
    "        \n",
    "        merge_summary[dataset_name] = {\n",
    "            'columns_added': new_columns,\n",
    "            'records_with_data': records_with_data,\n",
    "            'coverage_pct': (records_with_data / len(unified_df)) * 100\n",
    "        }\n",
    "        \n",
    "        print(f\"    Shape: {before_shape} â†’ {unified_df.shape}\")\n",
    "        print(f\"    Data coverage: {records_with_data}/{len(unified_df)} ({merge_summary[dataset_name]['coverage_pct']:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nâœ… ENHANCED UNIFIED DATASET CREATED: {strategy_name}\")\n",
    "    print(f\"   Final shape: {unified_df.shape}\")\n",
    "    print(f\"   Date range: {unified_df['date'].min().date()} to {unified_df['date'].max().date()}\")\n",
    "    print(f\"   Total data sources: {len(merge_summary)} (marketing + weather)\")\n",
    "    \n",
    "    return unified_df, merge_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c2d8dc0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ CREATING BOTH ENHANCED STRATEGIC DATASETS\n",
      "======================================================================\n",
      "\n",
      "ðŸ”— CREATING ENHANCED UNIFIED DATASET: Full Range + Weather (2022-2024)\n",
      "============================================================\n",
      "ðŸ“… Date range: 2022-01-03 to 2024-12-23\n",
      "ðŸ“Š Marketing datasets: 10\n",
      "ðŸŒ¤ï¸ Weather data: âœ…\n",
      "\n",
      "ðŸ“… Base dataset (sales): (156, 13)\n",
      "   Date range: 2022-01-03 to 2024-12-23\n",
      "\n",
      "  ðŸŒ¤ï¸ Merging weather data...\n",
      "    Filtered weather shape: (156, 5)\n",
      "    Shape: (156, 13) â†’ (156, 17)\n",
      "    Weather coverage: 156/156 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging email...\n",
      "    Filtered shape: (104, 13)\n",
      "    Renamed 1 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 17) â†’ (156, 18)\n",
      "    Data coverage: 104/156 (66.7%)\n",
      "\n",
      "  ðŸ”„ Merging search...\n",
      "    Filtered shape: (156, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 18) â†’ (156, 20)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging tv_branding...\n",
      "    Filtered shape: (156, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 20) â†’ (156, 22)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging social...\n",
      "    Filtered shape: (156, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 22) â†’ (156, 24)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging ooh...\n",
      "    Filtered shape: (156, 13)\n",
      "    Renamed 1 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 24) â†’ (156, 25)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging promo...\n",
      "    Filtered shape: (47, 13)\n",
      "    Renamed 1 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 25) â†’ (156, 26)\n",
      "    Data coverage: 47/156 (30.1%)\n",
      "\n",
      "  ðŸ”„ Merging radio_national...\n",
      "    Filtered shape: (156, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 26) â†’ (156, 28)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging radio_local...\n",
      "    Filtered shape: (156, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 28) â†’ (156, 30)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging tv_promo...\n",
      "    Filtered shape: (156, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (156, 30) â†’ (156, 32)\n",
      "    Data coverage: 156/156 (100.0%)\n",
      "\n",
      "âœ… ENHANCED UNIFIED DATASET CREATED: Full Range + Weather (2022-2024)\n",
      "   Final shape: (156, 32)\n",
      "   Date range: 2022-01-03 to 2024-12-23\n",
      "   Total data sources: 10 (marketing + weather)\n",
      "\n",
      "ðŸ”— CREATING ENHANCED UNIFIED DATASET: Complete Coverage + Weather (2022-2023)\n",
      "============================================================\n",
      "ðŸ“… Date range: 2022-01-03 to 2023-12-25\n",
      "ðŸ“Š Marketing datasets: 10\n",
      "ðŸŒ¤ï¸ Weather data: âœ…\n",
      "\n",
      "ðŸ“… Base dataset (sales): (104, 13)\n",
      "   Date range: 2022-01-03 to 2023-12-25\n",
      "\n",
      "  ðŸŒ¤ï¸ Merging weather data...\n",
      "    Filtered weather shape: (104, 5)\n",
      "    Shape: (104, 13) â†’ (104, 17)\n",
      "    Weather coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging email...\n",
      "    Filtered shape: (104, 13)\n",
      "    Renamed 1 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 17) â†’ (104, 18)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging search...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 18) â†’ (104, 20)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging tv_branding...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 20) â†’ (104, 22)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging social...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 22) â†’ (104, 24)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging ooh...\n",
      "    Filtered shape: (104, 13)\n",
      "    Renamed 1 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 24) â†’ (104, 25)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging promo...\n",
      "    Filtered shape: (30, 13)\n",
      "    Renamed 1 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 25) â†’ (104, 26)\n",
      "    Data coverage: 30/104 (28.8%)\n",
      "\n",
      "  ðŸ”„ Merging radio_national...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 26) â†’ (104, 28)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging radio_local...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 28) â†’ (104, 30)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "  ðŸ”„ Merging tv_promo...\n",
      "    Filtered shape: (104, 14)\n",
      "    Renamed 2 business columns\n",
      "    Removed 11 duplicate time features\n",
      "    Shape: (104, 30) â†’ (104, 32)\n",
      "    Data coverage: 104/104 (100.0%)\n",
      "\n",
      "âœ… ENHANCED UNIFIED DATASET CREATED: Complete Coverage + Weather (2022-2023)\n",
      "   Final shape: (104, 32)\n",
      "   Date range: 2022-01-03 to 2023-12-25\n",
      "   Total data sources: 10 (marketing + weather)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create Both Enhanced Strategic Datasets\n",
    "print(f\"\\nðŸš€ CREATING BOTH ENHANCED STRATEGIC DATASETS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "enhanced_unified_datasets = {}\n",
    "enhanced_merge_summaries = {}\n",
    "\n",
    "for strategy_key, strategy_info in enhanced_strategies.items():\n",
    "    strategy_name = strategy_info['name']\n",
    "    datasets = strategy_info['datasets']\n",
    "    weather = strategy_info['weather']\n",
    "    date_range = strategy_info['date_range']\n",
    "    \n",
    "    unified_df, merge_summary = create_enhanced_unified_dataset(\n",
    "        datasets, weather, date_range, strategy_name\n",
    "    )\n",
    "    \n",
    "    enhanced_unified_datasets[strategy_key] = unified_df\n",
    "    enhanced_merge_summaries[strategy_key] = merge_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1030396e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ENHANCED STRATEGIC COMPARISON\n",
      "==================================================\n",
      "\n",
      "ðŸŽ¯ FULL RANGE + WEATHER (2022-2024):\n",
      "   ðŸ“… Period: 2022-01-03 to 2024-12-23\n",
      "   ðŸ“Š Shape: (156, 32)\n",
      "   ðŸ“ˆ Weeks: 156\n",
      "   ðŸ“º Marketing Channels: 9\n",
      "   ðŸŒ¤ï¸ Weather Coverage: 100.0%\n",
      "   ðŸ”§ Total Features: 32\n",
      "   âœ… Completeness: 96.7%\n",
      "   ðŸ“‹ Data sources included:\n",
      "     1. weather: 100.0% coverage\n",
      "     2. email: 66.7% coverage\n",
      "     3. search: 100.0% coverage\n",
      "     4. tv_branding: 100.0% coverage\n",
      "     5. social: 100.0% coverage\n",
      "     6. ooh: 100.0% coverage\n",
      "     7. promo: 30.1% coverage\n",
      "     8. radio_national: 100.0% coverage\n",
      "     9. radio_local: 100.0% coverage\n",
      "     10. tv_promo: 100.0% coverage\n",
      "\n",
      "ðŸŽ¯ COMPLETE COVERAGE + WEATHER (2022-2023):\n",
      "   ðŸ“… Period: 2022-01-03 to 2023-12-25\n",
      "   ðŸ“Š Shape: (104, 32)\n",
      "   ðŸ“ˆ Weeks: 104\n",
      "   ðŸ“º Marketing Channels: 9\n",
      "   ðŸŒ¤ï¸ Weather Coverage: 100.0%\n",
      "   ðŸ”§ Total Features: 32\n",
      "   âœ… Completeness: 97.7%\n",
      "   ðŸ“‹ Data sources included:\n",
      "     1. weather: 100.0% coverage\n",
      "     2. email: 100.0% coverage\n",
      "     3. search: 100.0% coverage\n",
      "     4. tv_branding: 100.0% coverage\n",
      "     5. social: 100.0% coverage\n",
      "     6. ooh: 100.0% coverage\n",
      "     7. promo: 28.8% coverage\n",
      "     8. radio_national: 100.0% coverage\n",
      "     9. radio_local: 100.0% coverage\n",
      "     10. tv_promo: 100.0% coverage\n",
      "\n",
      "ðŸ“‹ ENHANCED COMPARISON SUMMARY:\n",
      "                               Strategy               Date Range  Weeks  Marketing Channels Weather Coverage  Total Features Completeness     Shape\n",
      "       Full Range + Weather (2022-2024) 2022-01-03 to 2024-12-23    156                   9           100.0%              32        96.7% (156, 32)\n",
      "Complete Coverage + Weather (2022-2023) 2022-01-03 to 2023-12-25    104                   9           100.0%              32        97.7% (104, 32)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Enhanced Comparison with Weather\n",
    "def compare_enhanced_strategies(unified_datasets, merge_summaries, strategies):\n",
    "    \"\"\"\n",
    "    Compare the two enhanced strategic approaches including weather\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š ENHANCED STRATEGIC COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for strategy_key, unified_df in unified_datasets.items():\n",
    "        strategy_info = strategies[strategy_key]\n",
    "        merge_summary = merge_summaries[strategy_key]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_sources = len(merge_summary)  # weather + marketing channels\n",
    "        marketing_channels = total_sources - 1  # subtract weather\n",
    "        total_weeks = len(unified_df)\n",
    "        total_features = unified_df.shape[1]\n",
    "        \n",
    "        # Calculate data completeness\n",
    "        non_date_cols = [col for col in unified_df.columns if col != 'date']\n",
    "        completeness = (unified_df[non_date_cols].notna().sum().sum() / \n",
    "                       (len(unified_df) * len(non_date_cols))) * 100\n",
    "        \n",
    "        # Weather coverage\n",
    "        weather_coverage = merge_summary.get('weather', {}).get('coverage_pct', 0)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Strategy': strategy_info['name'],\n",
    "            'Date Range': f\"{strategy_info['date_range'][0]} to {strategy_info['date_range'][1]}\",\n",
    "            'Weeks': total_weeks,\n",
    "            'Marketing Channels': marketing_channels,\n",
    "            'Weather Coverage': f\"{weather_coverage:.1f}%\",\n",
    "            'Total Features': total_features,\n",
    "            'Completeness': f\"{completeness:.1f}%\",\n",
    "            'Shape': unified_df.shape\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ {strategy_info['name'].upper()}:\")\n",
    "        print(f\"   ðŸ“… Period: {strategy_info['date_range'][0]} to {strategy_info['date_range'][1]}\")\n",
    "        print(f\"   ðŸ“Š Shape: {unified_df.shape}\")\n",
    "        print(f\"   ðŸ“ˆ Weeks: {total_weeks}\")\n",
    "        print(f\"   ðŸ“º Marketing Channels: {marketing_channels}\")\n",
    "        print(f\"   ðŸŒ¤ï¸ Weather Coverage: {weather_coverage:.1f}%\")\n",
    "        print(f\"   ðŸ”§ Total Features: {total_features}\")\n",
    "        print(f\"   âœ… Completeness: {completeness:.1f}%\")\n",
    "        \n",
    "        # Data source breakdown\n",
    "        print(f\"   ðŸ“‹ Data sources included:\")\n",
    "        for i, (source, info) in enumerate(merge_summary.items(), 1):\n",
    "            coverage = info['coverage_pct']\n",
    "            print(f\"     {i}. {source}: {coverage:.1f}% coverage\")\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(f\"\\nðŸ“‹ ENHANCED COMPARISON SUMMARY:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Compare enhanced strategies\n",
    "enhanced_comparison = compare_enhanced_strategies(\n",
    "    enhanced_unified_datasets, enhanced_merge_summaries, enhanced_strategies\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76d1cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ SAVING ENHANCED UNIFIED DATASETS\n",
      "=============================================\n",
      "  âœ… Saved: unified_dataset_full_range_2022_2024_with_weather.csv\n",
      "     Full Range + Weather (2022-2024, 9 channels + weather, 156 weeks)\n",
      "     Shape: (156, 32)\n",
      "  âœ… Saved: unified_dataset_complete_coverage_2022_2023_with_weather.csv\n",
      "     Complete Coverage + Weather (2022-2023, 10 channels + weather, 104 weeks)\n",
      "     Shape: (104, 32)\n",
      "  âœ… Saved: enhanced_unification_with_weather_report.json\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save Enhanced Datasets\n",
    "def save_enhanced_datasets(unified_datasets, strategies, merge_summaries):\n",
    "    \"\"\"\n",
    "    Save both enhanced unified datasets with weather integration\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ’¾ SAVING ENHANCED UNIFIED DATASETS\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    processed_dir = 'data/processed'\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    saved_files = {}\n",
    "    \n",
    "    for strategy_key, unified_df in unified_datasets.items():\n",
    "        strategy_info = strategies[strategy_key]\n",
    "        \n",
    "        # Create descriptive filename\n",
    "        if strategy_key == 'strategy_a':\n",
    "            filename = \"unified_dataset_full_range_2022_2024_with_weather.csv\"\n",
    "            description = \"Full Range + Weather (2022-2024, 9 channels + weather, 156 weeks)\"\n",
    "        else:\n",
    "            filename = \"unified_dataset_complete_coverage_2022_2023_with_weather.csv\"\n",
    "            description = \"Complete Coverage + Weather (2022-2023, 10 channels + weather, 104 weeks)\"\n",
    "        \n",
    "        # Save dataset\n",
    "        file_path = os.path.join(processed_dir, filename)\n",
    "        unified_df.to_csv(file_path, index=False)\n",
    "        \n",
    "        saved_files[strategy_key] = {\n",
    "            'filename': filename,\n",
    "            'path': file_path,\n",
    "            'description': description,\n",
    "            'shape': unified_df.shape\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ… Saved: {filename}\")\n",
    "        print(f\"     {description}\")\n",
    "        print(f\"     Shape: {unified_df.shape}\")\n",
    "    \n",
    "    # Save enhanced comparison report\n",
    "    import json\n",
    "    \n",
    "    def convert_numpy(obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, pd.Timestamp):\n",
    "            return obj.isoformat()\n",
    "        elif isinstance(obj, dict):\n",
    "            return {k: convert_numpy(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [convert_numpy(item) for item in obj]\n",
    "        elif hasattr(obj, 'item'):\n",
    "            return obj.item()\n",
    "        return obj\n",
    "    \n",
    "    enhanced_report = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'enhancement': 'Weather data integration added',\n",
    "        'weather_variables': [\n",
    "            'weather_temperature_mean',\n",
    "            'weather_temperature_max', \n",
    "            'weather_temperature_min',\n",
    "            'weather_sunshine_duration'\n",
    "        ],\n",
    "        'strategy_comparison': {\n",
    "            'strategy_a_full_range_weather': {\n",
    "                'description': 'Full Range + Weather (2022-2024)',\n",
    "                'date_range': strategies['strategy_a']['date_range'],\n",
    "                'shape': unified_datasets['strategy_a'].shape,\n",
    "                'marketing_channels': len(merge_summaries['strategy_a']) - 1,\n",
    "                'weather_coverage': merge_summaries['strategy_a']['weather']['coverage_pct'],\n",
    "                'filename': saved_files['strategy_a']['filename']\n",
    "            },\n",
    "            'strategy_b_complete_weather': {\n",
    "                'description': 'Complete Coverage + Weather (2022-2023)',\n",
    "                'date_range': strategies['strategy_b']['date_range'],\n",
    "                'shape': unified_datasets['strategy_b'].shape,\n",
    "                'marketing_channels': len(merge_summaries['strategy_b']) - 1,\n",
    "                'weather_coverage': merge_summaries['strategy_b']['weather']['coverage_pct'],\n",
    "                'filename': saved_files['strategy_b']['filename']\n",
    "            }\n",
    "        },\n",
    "        'merge_summaries': convert_numpy(merge_summaries),\n",
    "        'recommendation': {\n",
    "            'approach': 'Enhanced dual strategy with environmental context',\n",
    "            'benefits': [\n",
    "                'Weather factors for seasonality modeling',\n",
    "                'Temperature impact on consumer behavior',\n",
    "                'Sunshine duration for outdoor activity correlation',\n",
    "                'Environmental context for media effectiveness'\n",
    "            ],\n",
    "            'use_cases': {\n",
    "                'strategy_a': 'Trend analysis with weather patterns (recent 3 years)',\n",
    "                'strategy_b': 'Complete attribution with environmental factors (2 years)'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    report_path = os.path.join(processed_dir, \"enhanced_unification_with_weather_report.json\")\n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(enhanced_report, f, indent=2)\n",
    "    \n",
    "    print(f\"  âœ… Saved: enhanced_unification_with_weather_report.json\")\n",
    "    \n",
    "    return saved_files, enhanced_report\n",
    "\n",
    "# Save enhanced datasets\n",
    "enhanced_files, enhanced_report = save_enhanced_datasets(\n",
    "    enhanced_unified_datasets, enhanced_strategies, enhanced_merge_summaries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e162924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¯ ENHANCED STRATEGIC RECOMMENDATIONS\n",
      "=======================================================\n",
      "\n",
      "âœ… ENHANCED DATASETS SUCCESSFULLY CREATED!\n",
      "\n",
      "ðŸ“Š ENHANCED DATASET A - FULL RANGE + WEATHER:\n",
      "   ðŸ“ File: unified_dataset_full_range_2022_2024_with_weather.csv\n",
      "   ðŸ“ˆ Full Range + Weather (2022-2024, 9 channels + weather, 156 weeks)\n",
      "   ðŸŽ¯ Best for: Trend analysis with weather patterns\n",
      "   ðŸŒ¤ï¸ Weather integration: Environmental context for recent 3 years\n",
      "   âš ï¸  Limitation: Missing email channel attribution\n",
      "\n",
      "ðŸ“Š ENHANCED DATASET B - COMPLETE COVERAGE + WEATHER:\n",
      "   ðŸ“ File: unified_dataset_complete_coverage_2022_2023_with_weather.csv\n",
      "   ðŸ“ˆ Complete Coverage + Weather (2022-2023, 10 channels + weather, 104 weeks)\n",
      "   ðŸŽ¯ Best for: Complete attribution with environmental factors\n",
      "   ðŸŒ¤ï¸ Weather integration: Full channel interactions + weather\n",
      "   âš ï¸  Limitation: Less recent data (missing 2024)\n",
      "\n",
      "ðŸŒ¤ï¸ WEATHER ENHANCEMENTS:\n",
      "   ðŸŒ¡ï¸ Temperature variables: Mean, Max, Min (consumer comfort)\n",
      "   â˜€ï¸ Sunshine duration: Outdoor activity correlation\n",
      "   ðŸ“Š Perfect coverage: Weather data available for all periods\n",
      "   ðŸ”„ Seamless integration: Weekly Monday-start alignment\n",
      "\n",
      "ðŸš€ ENHANCED MMM DEVELOPMENT PATH:\n",
      "   1. ðŸ“Š EDA with weather correlation analysis\n",
      "   2. ðŸ¤– MMM with weather as external variables\n",
      "   3. ðŸŒ¡ï¸ Seasonal pattern analysis (temperature + media)\n",
      "   4. â˜€ï¸ Outdoor activity impact modeling\n",
      "   5. ðŸ“ˆ Weather-adjusted attribution insights\n",
      "\n",
      "ðŸ’¡ ENHANCED RECOMMENDATION:\n",
      "   ðŸŽ¯ Start with Dataset B for complete attribution + weather\n",
      "   ðŸ“ˆ Use Dataset A for trend validation with recent weather patterns\n",
      "   ðŸŒ¤ï¸ Weather provides crucial external variable context!\n",
      "   ðŸ” Analyze temperature-media effectiveness relationships\n",
      "\n",
      "âœ… ENHANCED DUAL UNIFICATION WITH WEATHER COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Final Enhanced Recommendations\n",
    "print(f\"\\nðŸŽ¯ ENHANCED STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(f\"\\nâœ… ENHANCED DATASETS SUCCESSFULLY CREATED!\")\n",
    "\n",
    "print(f\"\\nðŸ“Š ENHANCED DATASET A - FULL RANGE + WEATHER:\")\n",
    "print(f\"   ðŸ“ File: {enhanced_files['strategy_a']['filename']}\")\n",
    "print(f\"   ðŸ“ˆ {enhanced_files['strategy_a']['description']}\")\n",
    "print(f\"   ðŸŽ¯ Best for: Trend analysis with weather patterns\")\n",
    "print(f\"   ðŸŒ¤ï¸ Weather integration: Environmental context for recent 3 years\")\n",
    "print(f\"   âš ï¸  Limitation: Missing email channel attribution\")\n",
    "\n",
    "print(f\"\\nðŸ“Š ENHANCED DATASET B - COMPLETE COVERAGE + WEATHER:\")\n",
    "print(f\"   ðŸ“ File: {enhanced_files['strategy_b']['filename']}\")\n",
    "print(f\"   ðŸ“ˆ {enhanced_files['strategy_b']['description']}\")\n",
    "print(f\"   ðŸŽ¯ Best for: Complete attribution with environmental factors\")\n",
    "print(f\"   ðŸŒ¤ï¸ Weather integration: Full channel interactions + weather\")\n",
    "print(f\"   âš ï¸  Limitation: Less recent data (missing 2024)\")\n",
    "\n",
    "print(f\"\\nðŸŒ¤ï¸ WEATHER ENHANCEMENTS:\")\n",
    "print(f\"   ðŸŒ¡ï¸ Temperature variables: Mean, Max, Min (consumer comfort)\")\n",
    "print(f\"   â˜€ï¸ Sunshine duration: Outdoor activity correlation\")\n",
    "print(f\"   ðŸ“Š Perfect coverage: Weather data available for all periods\")\n",
    "print(f\"   ðŸ”„ Seamless integration: Weekly Monday-start alignment\")\n",
    "\n",
    "print(f\"\\nðŸš€ ENHANCED MMM DEVELOPMENT PATH:\")\n",
    "print(f\"   1. ðŸ“Š EDA with weather correlation analysis\")\n",
    "print(f\"   2. ðŸ¤– MMM with weather as external variables\")\n",
    "print(f\"   3. ðŸŒ¡ï¸ Seasonal pattern analysis (temperature + media)\")\n",
    "print(f\"   4. â˜€ï¸ Outdoor activity impact modeling\")\n",
    "print(f\"   5. ðŸ“ˆ Weather-adjusted attribution insights\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ ENHANCED RECOMMENDATION:\")\n",
    "print(f\"   ðŸŽ¯ Start with Dataset B for complete attribution + weather\")\n",
    "print(f\"   ðŸ“ˆ Use Dataset A for trend validation with recent weather patterns\")\n",
    "print(f\"   ðŸŒ¤ï¸ Weather provides crucial external variable context!\")\n",
    "print(f\"   ðŸ” Analyze temperature-media effectiveness relationships\")\n",
    "\n",
    "print(f\"\\nâœ… ENHANCED DUAL UNIFICATION WITH WEATHER COMPLETE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5428fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ FIXING EMAIL CAMPAIGN ISSUE\n",
      "========================================\n",
      "\n",
      "âŒ ISSUE IDENTIFIED:\n",
      "   Email campaigns only run through 2023 (no 2024 data)\n",
      "   But included in full range 2022-2024 dataset\n",
      "   This creates inconsistent channel mix between periods\n",
      "\n",
      "âœ… SOLUTION:\n",
      "   Remove email campaigns from full range dataset\n",
      "   Keep email in complete coverage dataset\n",
      "   Rename datasets with descriptive names\n",
      "\n",
      "ðŸ“‚ Loading current datasets...\n",
      "  Full range (2022-2024): (156, 32)\n",
      "  Complete coverage (2022-2023): (104, 32)\n",
      "\n",
      "ðŸ“§ Email campaign analysis:\n",
      "  Full range dataset (2022-2024):\n",
      "    Email non-zero weeks: 79\n",
      "    Email zero weeks: 25\n",
      "    2024 email non-zero weeks: 0\n",
      "    2024 email zero weeks: 52\n",
      "\n",
      "  Complete coverage dataset (2022-2023):\n",
      "    Email non-zero weeks: 79\n",
      "    Email zero weeks: 25\n",
      "\n",
      "ðŸ”§ Creating corrected datasets...\n",
      "  Full range: 32 â†’ 31 columns\n",
      "\n",
      "ðŸ’¾ Saving corrected datasets...\n",
      "  âœ… Complete channels (2022-2023): (104, 32)\n",
      "     File: mmm_dataset_complete_channels_2022_2023.csv\n",
      "     Includes: All channels including email campaigns\n",
      "  âœ… Consistent channels (2022-2024): (156, 31)\n",
      "     File: mmm_dataset_consistent_channels_2022_2024.csv\n",
      "     Excludes: Email campaigns (no 2024 data)\n",
      "  âœ… Correction report: unified_datasets_correction_report.json\n",
      "\n",
      "ðŸ“‹ CORRECTION COMPLETE!\n",
      "========================================\n",
      "âœ… Email campaigns removed from full range dataset\n",
      "âœ… Datasets renamed with descriptive names\n",
      "âœ… Channel consistency maintained across time periods\n",
      "\n",
      "ðŸŽ¯ RECOMMENDED USAGE:\n",
      "  â€¢ For MMM modeling: Use 'mmm_dataset_consistent_channels_2022_2024.csv'\n",
      "  â€¢ For email analysis: Use 'mmm_dataset_complete_channels_2022_2023.csv'\n",
      "  â€¢ Promotions are sparse by design (normal campaign behavior)\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Fix Email Campaign Issue\n",
    "print(f\"\\nðŸ”§ FIXING EMAIL CAMPAIGN ISSUE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\nâŒ ISSUE IDENTIFIED:\")\n",
    "print(f\"   Email campaigns only run through 2023 (no 2024 data)\")\n",
    "print(f\"   But included in full range 2022-2024 dataset\")\n",
    "print(f\"   This creates inconsistent channel mix between periods\")\n",
    "\n",
    "print(f\"\\nâœ… SOLUTION:\")\n",
    "print(f\"   Remove email campaigns from full range dataset\")\n",
    "print(f\"   Keep email in complete coverage dataset\")\n",
    "print(f\"   Rename datasets with descriptive names\")\n",
    "\n",
    "# Load current datasets\n",
    "print(f\"\\nðŸ“‚ Loading current datasets...\")\n",
    "full_range_df = pd.read_csv('data/processed/unified_dataset_full_range_2022_2024_with_weather.csv')\n",
    "complete_coverage_df = pd.read_csv('data/processed/unified_dataset_complete_coverage_2022_2023_with_weather.csv')\n",
    "\n",
    "print(f\"  Full range (2022-2024): {full_range_df.shape}\")\n",
    "print(f\"  Complete coverage (2022-2023): {complete_coverage_df.shape}\")\n",
    "\n",
    "# Check email coverage\n",
    "full_range_df['date'] = pd.to_datetime(full_range_df['date'])\n",
    "complete_coverage_df['date'] = pd.to_datetime(complete_coverage_df['date'])\n",
    "\n",
    "print(f\"\\nðŸ“§ Email campaign analysis:\")\n",
    "print(f\"  Full range dataset (2022-2024):\")\n",
    "print(f\"    Email non-zero weeks: {(full_range_df['email_email_campaigns'] > 0).sum()}\")\n",
    "print(f\"    Email zero weeks: {(full_range_df['email_email_campaigns'] == 0).sum()}\")\n",
    "\n",
    "full_range_2024 = full_range_df[full_range_df['date'].dt.year == 2024]\n",
    "print(f\"    2024 email non-zero weeks: {(full_range_2024['email_email_campaigns'] > 0).sum()}\")\n",
    "print(f\"    2024 email zero weeks: {len(full_range_2024) - (full_range_2024['email_email_campaigns'] > 0).sum()}\")\n",
    "\n",
    "print(f\"\\n  Complete coverage dataset (2022-2023):\")\n",
    "print(f\"    Email non-zero weeks: {(complete_coverage_df['email_email_campaigns'] > 0).sum()}\")\n",
    "print(f\"    Email zero weeks: {(complete_coverage_df['email_email_campaigns'] == 0).sum()}\")\n",
    "\n",
    "# Create corrected full range dataset (without email)\n",
    "print(f\"\\nðŸ”§ Creating corrected datasets...\")\n",
    "full_range_corrected = full_range_df.drop(columns=['email_email_campaigns'])\n",
    "\n",
    "print(f\"  Full range: {full_range_df.shape[1]} â†’ {full_range_corrected.shape[1]} columns\")\n",
    "\n",
    "# Save corrected datasets with proper names\n",
    "print(f\"\\nðŸ’¾ Saving corrected datasets...\")\n",
    "\n",
    "# Complete coverage dataset (keeps email) - rename for clarity\n",
    "complete_coverage_path = 'data/processed/mmm_dataset_complete_channels_2022_2023.csv'\n",
    "complete_coverage_df.to_csv(complete_coverage_path, index=False)\n",
    "print(f\"  âœ… Complete channels (2022-2023): {complete_coverage_df.shape}\")\n",
    "print(f\"     File: mmm_dataset_complete_channels_2022_2023.csv\")\n",
    "print(f\"     Includes: All channels including email campaigns\")\n",
    "\n",
    "# Full range dataset (no email) - rename for clarity  \n",
    "full_range_path = 'data/processed/mmm_dataset_consistent_channels_2022_2024.csv'\n",
    "full_range_corrected.to_csv(full_range_path, index=False)\n",
    "print(f\"  âœ… Consistent channels (2022-2024): {full_range_corrected.shape}\")\n",
    "print(f\"     File: mmm_dataset_consistent_channels_2022_2024.csv\")\n",
    "print(f\"     Excludes: Email campaigns (no 2024 data)\")\n",
    "\n",
    "# Create correction summary\n",
    "correction_summary = {\n",
    "    'issue_identified': 'Email campaigns only available through 2023, but included in 2022-2024 dataset',\n",
    "    'solution_applied': 'Removed email campaigns from full range dataset to maintain consistent channel mix',\n",
    "    'datasets_created': {\n",
    "        'complete_channels_2022_2023': {\n",
    "            'file': 'mmm_dataset_complete_channels_2022_2023.csv',\n",
    "            'shape': complete_coverage_df.shape,\n",
    "            'date_range': f\"{complete_coverage_df['date'].min().date()} to {complete_coverage_df['date'].max().date()}\",\n",
    "            'channels': 'All channels including email campaigns',\n",
    "            'use_case': 'Analysis of complete channel mix for 2022-2023 period'\n",
    "        },\n",
    "        'consistent_channels_2022_2024': {\n",
    "            'file': 'mmm_dataset_consistent_channels_2022_2024.csv', \n",
    "            'shape': full_range_corrected.shape,\n",
    "            'date_range': f\"{full_range_corrected['date'].min().date()} to {full_range_corrected['date'].max().date()}\",\n",
    "            'channels': 'All channels except email campaigns',\n",
    "            'use_case': 'MMM modeling with consistent channel mix across full time range'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save correction report\n",
    "import json\n",
    "correction_path = 'data/processed/unified_datasets_correction_report.json'\n",
    "with open(correction_path, 'w') as f:\n",
    "    json.dump(correction_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"  âœ… Correction report: unified_datasets_correction_report.json\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ CORRECTION COMPLETE!\")\n",
    "print(f\"=\" * 40)\n",
    "print(f\"âœ… Email campaigns removed from full range dataset\")\n",
    "print(f\"âœ… Datasets renamed with descriptive names\")\n",
    "print(f\"âœ… Channel consistency maintained across time periods\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ RECOMMENDED USAGE:\")\n",
    "print(f\"  â€¢ For MMM modeling: Use 'mmm_dataset_consistent_channels_2022_2024.csv'\")\n",
    "print(f\"  â€¢ For email analysis: Use 'mmm_dataset_complete_channels_2022_2023.csv'\")\n",
    "print(f\"  â€¢ Promotions are sparse by design (normal campaign behavior)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a22b9c",
   "metadata": {},
   "source": [
    "## Enhanced Dual Unification with Weather Complete! ðŸŒ¤ï¸\n",
    "\n",
    "### ðŸŽ¯ **Enhanced Strategic Approach:**\n",
    "\n",
    "#### **Dataset A - Full Range + Weather (2022-2024):**\n",
    "- **Period**: 156 weeks with weather context\n",
    "- **Channels**: 9 marketing + 4 weather variables\n",
    "- **Strength**: Recent trends with environmental factors\n",
    "- **Use Case**: Weather-adjusted trend analysis and forecasting\n",
    "\n",
    "#### **Dataset B - Complete Coverage + Weather (2022-2023):**\n",
    "- **Period**: 104 weeks with complete data + weather\n",
    "- **Channels**: 10 marketing + 4 weather variables  \n",
    "- **Strength**: Full attribution with environmental context\n",
    "- **Use Case**: Complete channel interactions with weather impact\n",
    "\n",
    "### ðŸŒ¤ï¸ **Weather Variables Integrated:**\n",
    "- **Temperature Mean/Max/Min**: Consumer comfort and behavior\n",
    "- **Sunshine Duration**: Outdoor activity correlation\n",
    "- **Perfect Coverage**: 100% weather data availability\n",
    "- **Aligned Timing**: Monday-start weekly structure\n",
    "\n",
    "### ðŸ“Š **Enhanced Files Created:**\n",
    "- `unified_dataset_full_range_2022_2024_with_weather.csv`\n",
    "- `unified_dataset_complete_coverage_2022_2023_with_weather.csv`\n",
    "- `enhanced_unification_with_weather_report.json`\n",
    "\n",
    "### ðŸš€ **Next Phase Benefits:**\n",
    "- **Environmental Context**: Weather as external MMM variables\n",
    "- **Seasonal Insights**: Temperature-media effectiveness patterns\n",
    "- **Behavioral Factors**: Weather impact on consumer activity\n",
    "- **Enhanced Attribution**: Channel performance by weather conditions\n",
    "\n",
    "**This enhanced approach provides comprehensive business intelligence with environmental context for superior MMM insights!** ðŸ“ˆðŸŒ¤ï¸ "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
